Metadata-Version: 2.1
Name: DataQualityFrameworkGovernance
Version: 0.0.10.1
Summary: Data Quality Framework Governance is a structured approach to assessing, monitoring, and improving the quality of data.
Author-email: Rajith Prabhakaran <rajith.prabhakaran@yahoo.com>
Project-URL: Homepage, https://github.com/RajithPrabakaran/DataQualityFrameworkGovernance
Project-URL: Bug Tracker, https://github.com/RajithPrabakaran/DataQualityFrameworkGovernance/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE


  

# Data Quality Framework Governance (DQFG)
  

**Data Quality Framework Governance** is a structured approach to assessing, monitoring, and improving the quality of data. An effective **Data Quality Framework** considers these dimensions and integrates them into a structured approach to ensure that data serves its intended purpose, supports informed decision-making, and maintains the trust of users and stakeholders.

**Data Quality** is an ongoing process that requires continuous monitoring, assessment, and improvement to adapt to changing data requirements and evolving business needs.



**Installation:**

	pip install DataQualityFrameworkGovernance

  

**Example:** To call functions from the library.

	from Uniqueness import duplicate_rows
	print(duplicate_rows(dataframe))


**Library structure**

****
  

<details>
<summary><b>Accuracy</b></summary>

<ul>

<details>
<summary><i>accuracy_tolerance_numeric</i></summary>

Calculating data quality accuracy of a set of values (base values) by comparing them to a known correct value (lookup value) by setting a user-defined tolerance percentage, applicable for numeric values.

	from  Accuracy  import  accuracy_tolerance_numeric
	print(accuracy_tolerance_numeric(dataframe, base_column, lookup_column, tolerance_percentage))

</details>

<details>
<summary><i>email_pattern</i></summary>

Validating accuracy of email addresses in a dataset by verifying that they follow a valid email format.

	from  Accuracy  import  email_pattern
	print(email_pattern(dataframe,email_column_name))

</details>

<details>
<summary><i>filter_number_range</i></summary>

Number range ensures that data values are accurate and conform to expected values or constraints. It is applicable to a variety of contexts, including exam scores, weather conditions, pricing, stock prices, age, income, speed limits for vehicles, water levels, and numerous other scenarios.

	from  Accuracy  import  filter_number_range
	print(filter_number_range(dataframe, range_column_name, lower_bound, upper_bound))

</details>

<details>
<summary><i>filter_datetime_range</i></summary>

The datetime range filter guarantees the accuracy and adherence of data values to predetermined criteria or constraints. It is applicable to a variety of contexts, including capturing outliers in date of birth, age and many more.

	from  Accuracy  import  filter_datetime_range
	print(filter_datetime_range(location, range_column_name, from_date, to_date, date_format))

**Important**: Specify date format in *'%Y-%m-%d %H:%M:%S.%f'*  ***(It can be specified in any format, parameter value to be aligned appropriately).***

</details>

</ul>
</details>

<details>
<summary><b>Completeness</b></summary>

<ul>

<details>
<summary><i>missing_values</i></summary>

Summary of missing values in each column.

	from  Completeness  import  missing_values
	print(missing_values(dataframe))

</details>

<details>
<summary><i>overall_completeness_percentage</i></summary>

Percentage of missing values in a DataFrame. 

  
	from  Completeness  import  overall_completeness_percentage
	print(overall_completeness_percentage(dataframe))

</details>

</ul>
</details>

<details>
<summary><b>Consistency</b></summary>

<ul>

<details>
<summary><i>start_end_date_consistency</i></summary>

If the data in two columns is consistent, check if the "Start Date" and "End Date" column are in the correct chronological order. 

  
  	from  Consistency  import  start_end_date_consistency
	print(start_end_date_consistency(dataframe, start_date_column_name, end_date_column_name, date_format))

**Important**: Specify date format in *'%Y-%m-%d %H:%M:%S.%f'*  ***(It can be specified in any format, parameter value to be aligned appropriately).***

</details>


<details>
<summary><i>count_start_end_date_consistency</i></summary>

Count of data in two columns is consistent, check if the "Start Date" and "End Date" column are in the correct chronological order. 

  
  	from  Consistency  import  count_start_end_date_consistency
	print(count_start_end_date_consistency(dataframe, start_date_column_name, end_date_column_name, date_format))
  
**Important**: Specify date format in *'%Y-%m-%d %H:%M:%S.%f'*  ***(It can be specified in any format, parameter value to be aligned appropriately).***

</details>

</ul>
</details>
  

<details>
<summary><b>Uniqueness</b></summary>

<ul>

<details>
<summary><i>duplicate_rows</i></summary>

Identify and display **duplicate** rows in a dataset. 

  
	from  Uniqueness  import  duplicate_rows
	print(duplicate_rows(dataframe))

</details>

<details>
<summary><i>unique_column_values</i></summary>

Identify and display **unique** values in a dataset. 

	from  Uniqueness  import  unique_column_values
	print(unique_column_values(dataframe, column_name))

</details>

<details>
<summary><i>unique_column_count</i></summary>

Identify and count **unique** values in a dataset. 

	from  Uniqueness  import  unique_column_count
	print(unique_column_count(dataframe, column_name))

</details>

</ul>
</details>


<details>
<summary><b>Validity</b></summary>

<ul>

<details>
<summary><i>validate_age</i></summary>

Validate age based on the criteria in a dataset. 

  	from  Validity  import  validate_age
	print(validate_age(dataframe, age_column, min_age, max_age))

</details>

<details>
<summary><i>validate_age_count</i></summary>

Count age based on the criteria in a dataset. 

  	from  Validity  import  validate_age_count
	print(validate_age_count(dataframe, age_column, min_age, max_age))

</details>

</ul>
</details>
  

<details>
<summary><b>Datastats</b></summary>

<ul>

<details>
<summary><i>count_rows</i></summary>

Count the number of rows in a DataFrame. 
  
  	from  Datastats  import  count_rows
	print(count_rows(dataframe))

</details>

<details>
<summary><i>count_columns</i></summary>

Count the number of columns in a DataFrame. 

    
  	from  Datastats  import  count_columns
	print(count_columns(dataframe))

</details>

<details>
<summary><i>count_dataset</i></summary>

Count the number of rows & columns in a DataFrame. 
    
  	from  Datastats  import  count_dataset
	print(count_dataset(dataframe))

</details>

</ul>
</details>
  

****

  

  

**Supporting python libraries:**

  

- Pandas
- re
  

  

****

  

[Homepage](https://github.com/RajithPrabakaran/DataQualityFrameworkGovernance)

  

  

[Bug Tracker](https://github.com/RajithPrabakaran/DataQualityFrameworkGovernance/issues)

  

  

[Github-flavored Markdown](https://guides.github.com/features/mastering-markdown/)
