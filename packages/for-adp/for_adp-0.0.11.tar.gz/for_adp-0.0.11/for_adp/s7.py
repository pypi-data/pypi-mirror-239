def s7():
    """
    ì œ 7 ì¥
    íšŒê·€ë¶„ì„ì˜ ì´í•´
    7.1 ë‹¨ìˆœ ì„ í˜•íšŒê·€ (Simple linear regression)
    ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê¸°í˜¸ë“¤
    â€¢ ë°˜ì‘ë³€ìˆ˜ ğ‘¦ğ‘–
    , ğ‘– = 1, ..., ğ‘›
    â€¢ ë…ë¦½ë³€ìˆ˜ ğ‘¥ğ‘–
    , ğ‘– = 1, ..., ğ‘›
    â€¢ ì¡ìŒë³€ìˆ˜ ğ‘’ğ‘–
    , ğ‘– = 1, ..., ğ‘›
    y =
    â›âœâœâœâœâœ
    â
    ğ‘¦1
    ğ‘¦2
    ...
    ğ‘¦ğ‘›
    ââŸâŸâŸâŸâŸ
    â 
    , ğ‘‹ğ›½ =
    â›âœâœâœâœâœâœâœ
    â
    1 ğ‘¥1
    1 ğ‘¥2
    ... ...
    1 ğ‘¥ğ‘›âˆ’1
    1 ğ‘¥ğ‘›
    ââŸâŸâŸâŸâŸâŸâŸ
    â 
    (
    ğ›½0
    ğ›½1
    ) , ğ‘’ = â›âœâœâœâœâœ
    â
    ğ‘’1
    ğ‘’2
    ...
    ğ‘’ğ‘›
    ââŸâŸâŸâŸâŸ
    â 
    ëª¨ë¸ ê°€ì •
    ë°˜ì‘ë³€ìˆ˜ì˜ ê´€ì°°ê°’ë“¤ì€ ë‹¤ìŒê³¼ ê°™ì€ ëª¨ë¸ì„ í†µí•´ì„œ ë°œìƒë˜ì—ˆë‹¤ê³  ê°€ì •í•œë‹¤.
    ğ‘¦ âˆ¼ ğ’©(ğ‘‹ğ›½, ğœ2
    ğ¼)
    â€¢ ê´€ì°°ê°’ ğ‘¦ğ‘–ì€ ë…ë¦½ë³€ìˆ˜ ğ‘¥ğ‘–ì™€ ì¡ìŒ ğ‘’ğ‘–ì˜ ì„ í˜•ê²°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤.
    ğ‘¦ğ‘– = ğ›½0 + ğ›½1ğ‘¥ğ‘– + ğ‘’ğ‘–
    , ğ‘– = 1, ..., ğ‘›
    â€¢ ì¡ìŒ ğ‘’ğ‘–ë“¤ì˜ ë¶„í¬ëŠ” í‰ê· ì´ 0ì´ê³  ë¶„ì‚°ì´ ğœ
    2ì¸ ë…ë¦½ì¸ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •
    â€¢ ì›ë˜ ì¡ìŒ ë¶„í¬ì— ëŒ€í•œ ê°€ì •ì´ ì—†ì—ˆìœ¼ë‚˜, ì¶”í›„ì— ì¶”ê°€ ë¨.
    Best fitting line
    ğ›½ = (ğ‘‹ Ì‚ ğ‘‡ ğ‘‹)âˆ’1 ğ‘‹ğ‘‡ ğ‘¦
    íšŒê·€ë¶„ì„ ê³„ìˆ˜ ì¶”ì •ì„ í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒì˜ ìŠ¬ê¸°ë¡œìš´ í†µê³„ìƒí™œ ì˜ìƒì„ ì°¸ê³ í•˜ì.
    íšŒê·€ë¶„ì„ì˜ ì´í•´ | 139
    â€¢ ì˜ìƒ1
    â€¢ ì˜ìƒ2
    # íŒŒì´ì¬ ì½”ë“œ
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.datasets import load_iris
    iris = load_iris()
    iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)
    iris.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width'] #ì»¬ëŸ¼ëª… ë³€ê²½ì‹œ
    x = iris['Petal_Width']
    y = iris['Petal_Length']
    data_X = np.column_stack((np.ones(len(x)), x))
    beta = np.linalg.solve(np.dot(data_X.T, data_X), np.dot(data_X.T, y))
    plt.scatter(x, y, color='blue')
    ^à¼ˆ <matplotlib.collections.PathCollection object at 0x000001AB9878D248>
    plt.xlabel("Width")
    ^à¼ˆ Text(0.5, 0, 'Width')
    plt.ylabel("Length")
    ^à¼ˆ Text(0, 0.5, 'Length')
    plt.axhline(y=np.mean(y), color='blue', linestyle='-')
    ^à¼ˆ <matplotlib.lines.Line2D object at 0x000001ABA23EB508>
    plt.plot(x, np.dot(data_X, beta), color='red', linestyle='-')
    ^à¼ˆ [<matplotlib.lines.Line2D object at 0x000001ABA23EB448>]
    140 | íšŒê·€ë¶„ì„ì˜ ì´í•´
    7
    plt.show()
    0.0 0.5 1.0 1.5 2.0 2.5
    Width
    1
    2
    3
    4
    5
    6
    7
    Length
    â€¢ íŒŒë€ìƒ‰ ì„ ì˜ ì˜ë¯¸: ë…ë¦½ë³€ìˆ˜ ğ‘‹ì˜ ì •ë³´ê°€ ì—†ì—ˆë‹¤ë©´ ë°˜ì‘ ë³€ìˆ˜ ğ‘¦ì— ëŒ€í•œ ìµœì  ì¶”ì •ì¹˜ëŠ” ğ‘¦ì˜ í‘œë³¸
    í‰ê· ì„ ì‚¬ìš©í•´ì„œ ì˜ˆì¸¡
    â€¢ ë¹¨ê°„ìƒ‰ ì„ ì˜ ì˜ë¯¸: ë…ë¦½ë³€ìˆ˜ ğ‘‹ì˜ ì •ë³´ê°€ ì¶”ê°€ëœ ìµœì ì˜ ì˜ˆì¸¡ ì§ì„ 
    íŒŒì´ì¬ì—ì„œ íšŒê·€ë¶„ì„
    from statsmodels.formula.api import ols
    model = ols("Petal_Length ~ Petal_Width", data=iris).fit()
    model.summary()
    ^à¼ˆ <class 'statsmodels.iolib.summary.Summary'>
    ^à¼ˆ ""
    ^à¼ˆ OLS Regression Results
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Dep. Variable: Petal_Length Rà¼¡squared: 0.927
    ^à¼ˆ Model: OLS Adj. Rà¼¡squared: 0.927
    ^à¼ˆ Method: Least Squares Fà¼¡statistic: 1882.
    ^à¼ˆ Date: í† , 28 10 2023 Prob (Fà¼¡statistic): 4.68e-86
    ^à¼ˆ Time: 14:01:32 Log-Likelihood: -101.18
    ^à¼ˆ No. Observations: 150 AIC: 206.4
    ^à¼ˆ Df Residuals: 148 BIC: 212.4
    ^à¼ˆ Df Model: 1
    ^à¼ˆ Covariance Type: nonrobust
    ^à¼ˆ ===============================================================================
    ^à¼ˆ coef std err t P>|t| [0.025 0.975]
    ë‹¨ìˆœ ì„ í˜•íšŒê·€ (Simple linear regression) | 141
    ^à¼ˆ -------------------------------------------------------------------------------
    ^à¼ˆ Intercept 1.0836 0.073 14.850 0.000 0.939 1.228
    ^à¼ˆ Petal_Width 2.2299 0.051 43.387 0.000 2.128 2.332
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Omnibus: 2.438 Durbin-Watson: 1.430
    ^à¼ˆ Prob(Omnibus): 0.295 Jarque-Bera (JB): 1.966
    ^à¼ˆ Skew: 0.211 Prob(JB): 0.374
    ^à¼ˆ Kurtosis: 3.369 Cond. No. 3.70
    ^à¼ˆ ==============================================================================
    ^à¼ˆ
    ^à¼ˆ Notes:
    ^à¼ˆ [1] Standard Errors assume that the covariance matrix of the errors is correctly â†©
    specified.
    ^à¼ˆ ""
    ê³„ìˆ˜ì— ë”°ë¥¸ ëª¨ë¸ì‹
    ğ‘ƒ ğ‘’ğ‘¡ğ‘ğ‘™ ğ¿ğ‘’ğ‘›ğ‘”ğ‘¡â„ = 1.08356 + 2.22994 Ã— ğ‘ƒ ğ‘’ğ‘¡ğ‘ğ‘™ ğ‘Šğ‘–ğ‘‘ğ‘¡â„
    íšŒê·€ë¶„ì„ì˜ íš¨ìš©ì„± ì¸¡ì • ì§€í‘œë“¤
    SST, SSM, and SSE
    ë¶“ê½ƒì˜ ê½ƒì ê¸¸ì´ ì•„ë¬´ëŸ° ì¶”ê°€ ì •ë³´ê°€ ì—†ì„ ê²½ìš° í‰ê·  ( Ì„ğ‘¦ ) ìœ¼ë¡œ ì˜ˆì¸¡í•  ê²ƒì´ë‹¤. ì´ë ‡ê²Œ ë°˜ì‘ë³€ìˆ˜ í‰ê· ê°’
    ( Ì„ğ‘¦ ) ì—ì„œ ê° ê´€ì¸¡ì¹˜ë“¤ê¹Œì§€ì˜ ë³€ë™ì„±ì˜ ì œê³±í•©ì€ ë‹¤ìŒê³¼ ê°™ì´ ë¶„í•´ í•  ìˆ˜ ìˆìŒ.
    142 | íšŒê·€ë¶„ì„ì˜ ì´í•´
    7
    ğ‘†ğ‘†ğ‘‡ = ğ‘†ğ‘†ğ‘… + ğ‘†ğ‘†ğ¸
    â€¢ ê´€ì¸¡ì¹˜ë“¤ì˜ í¸ì°¨ ì œê³±í•© (SST): âˆ‘(ğ‘¦ğ‘– âˆ’ Ì„ğ‘¦)2
    â€“ ë¶“ê½ƒì˜ ê½ƒì ë„ˆë¹„ ì •ë³´( ğ‘‹1
    )ë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒê·€ëª¨ë¸ì„ ìˆ˜ë¦½í•˜ì—¬ ì˜ˆì¸¡ ( Ì‚ğ‘¦ğ‘–
    )
    â€¢ ì˜ˆì¸¡ì¹˜ì˜ ì˜¤ì°¨ë“¤ì˜ ì œê³±í•©(SSE): âˆ‘(ğ‘¦ğ‘– âˆ’ Ì‚ğ‘¦ğ‘–
    )
    2
    â€¢ í–¥ìƒëœ ì˜ˆì¸¡ë ¥ë“¤ì˜ ì œê³±í•©(SSR): âˆ‘( Ì‚ğ‘¦ğ‘– âˆ’ Ì„ğ‘¦)2
    â€“ íšŒê·€ëª¨ë¸ì„ ì‚¬ìš© ì˜ˆì¸¡í•¨ìœ¼ë¡œì„œ í–¥ìƒëœ ì˜ˆì¸¡ë ¥ ( Ì‚ğ‘¦ğ‘– âˆ’ Ì„ğ‘¦ )
    7.2 íšŒê·€ë¶„ì„ ANOVA
    ê·€ë¬´ê°€ì„¤ vs. ëŒ€ë¦½ê°€ì„¤
    â€¢ ğ»0
    : ëª¨ë“  íšŒê·€ê³„ìˆ˜ë“¤ì´ 0ì´ë‹¤. ğ›½1 = 0
    â€¢ ğ»ğ´: 0ì´ ì•„ë‹Œ íšŒê·€ê³„ìˆ˜ê°€ ì¡´ì¬í•œë‹¤. ğ›½1 â‰  0
    ê²€ì •í†µê³„ëŸ‰
    ğ¹ = ğ‘†ğ‘†ğ‘…/1
    ğ‘†ğ‘†ğ¸/(ğ‘› âˆ’ 2) âˆ¼ ğ¹1,ğ‘›âˆ’2
    â€¢ ANOVAì—ì„œ ê·¸ë£¹ë³„ í‰ê· ì´ ë‹¤ë¥´ë‹¤ê³  ê²°ë¡  ë‚´ë¦¬ëŠ” ë…¼ë¦¬ì™€ ë™ì¼í•¨.
    â€¢ íšŒê·€ë¶„ì„ì„ í†µí•´ì„œ í–¥ìƒëœ ì˜ˆì¸¡ íš¨ê³¼ (ë¶„ì ë¶€ë¶„)ê°€ ëª¨ë¸ì˜ ì¡ìŒë³´ë‹¤ í›¨ì”¬ í¬ë‹¤ë©´, íšŒê·€ë¶„ì„
    ëª¨ë¸ì˜ íš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ê°€ ìˆë‹¤ê³  íŒë‹¨í•œë‹¤.
    â€¢ ë…ë¦½ë³€ìˆ˜ë¥¼ ê³ ë ¤í•˜ëŠ” ê²ƒì´ ì •ë§ íš¨ê³¼ê°€ ìˆëŠ”ì§€ë¥¼ ê²€ì •í•œë‹¤.
    â€¢ ì„¤ëª…ë ¥ì´ ë§ì´ ì¢‹ì•„ì¡ŒëŠ”ì§€ë¥¼ ì²´í¬!
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    model = ols("Petal_Length ~ Petal_Width", data=iris).fit()
    sm.stats.anova_lm(model)
    ^à¼ˆ df sum_sq mean_sq F PR(>F)
    ^à¼ˆ Petal_Width 1.0 430.480647 430.480647 1882.452368 4.675004e-86
    ^à¼ˆ Residual 148.0 33.844753 0.228681 NaN NaN
    â€¢ ìœ ì˜ìˆ˜ì¤€ 5% í•˜ì—ì„œ F value (1882.5)ì™€ ëŒ€ì‘í•˜ëŠ” pâ€‘value 2.2âˆ’16ì„ ê³ ë ¤í•  ë•Œ, ë„ˆë¬´ ì‘ìœ¼ë¯€
    ë¡œ, ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•œë‹¤.
    íšŒê·€ë¶„ì„ ANOVA | 143
    ì•Œì•„ë‘ë©´ ì¢‹ì€ ë¶„í¬ ì •ë³´
    ììœ ë„ê°€ ğ‘ì¸ ğ‘¡ ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” í™•ë¥ ë³€ìˆ˜ë¥¼ ì œê³±í•˜ë©´ ììœ ë„ê°€ 1, ğ‘ì¸ F ë¶„í¬ë¥¼ ë”°ë¥´ê²Œ ëœë‹¤.
    (ğ‘¡ğ‘›âˆ’2)
    2 = ğ¹1,ğ‘›âˆ’2
    íšŒê·€ë¶„ì„ì˜ ì„±ëŠ¥ì¸¡ì • ì§€í‘œ â€‘ ğ‘…2 vs. adjusted ğ‘…2
    ğ‘…2
    â€‘ íšŒê·€ ì§ì„ ì˜ ì„±ëŠ¥ì€ ì–¼ë§ˆë‚˜ ì¢‹ì•„?
    â€¢ íšŒê·€ì§ì„ ìœ¼ë¡œ ì¸í•˜ì—¬ í–¥ìƒëœ ì˜ˆì¸¡ë ¥ì´ ì „ì²´ ê´€ì¸¡ì¹˜ ë³€ë™ì„±ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨
    ğ‘…2 =
    ğ‘†ğ‘†ğ‘…
    ğ‘†ğ‘†ğ‘‡ = 1 âˆ’
    ğ‘†ğ‘†ğ¸
    ğ‘†ğ‘†ğ‘‡
    â€¢ ğ‘…2 í•´ì„: ğ‘…2 ë§Œí¼ì˜ ë°ì´í„° ë³€ë™ì„±ì´ ë…ë¦½ë³€ìˆ˜ì— ì˜í•˜ì—¬ ì„¤ëª…ë¨
    â€¢ ì£¼ì˜: Adjusted ğ‘…2ëŠ” ğ‘…2ì²˜ëŸ¼ í•´ì„í•˜ë©´ ì•ˆ ë¨.
    Adjusted ğ‘…2
    â€‘ ëª¨ë¸ ë³µì¡ë„ë¥¼ ê³ ë ¤í•œ ì§€í‘œ
    â€¢ ëª¨ë¸ì— ë“¤ì–´ìˆëŠ” ë…ë¦½ ë³€ìˆ˜ ê°¯ìˆ˜ ğ‘ ê°€ ë§ì•„ì§€ë©´ ğ‘…2ì€ í•­ìƒ ë†’ì•„ì§€ëŠ” ê²½í–¥ì„ ë³´ì¸ë‹¤.
    â€¢ ë³€ìˆ˜ ê°¯ìˆ˜ê°€ ë‹¤ë¥¸ ëª¨ë¸ê°„ ì í•©ë„ë¥¼ ë¹„êµí•˜ë ¤ í•œë‹¤ë©´ adjusted ğ‘…2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„êµí•œë‹¤.
    ğ‘…2
    ğ‘ = 1 âˆ’
    ğ‘†ğ‘†ğ¸/(ğ‘› âˆ’ ğ‘ âˆ’ 1)
    ğ‘†ğ‘†ğ‘‡ /(ğ‘› âˆ’ 1) = 1 âˆ’
    ğ‘› âˆ’ 1
    ğ‘› âˆ’ ğ‘ âˆ’ 1
    (1 âˆ’ ğ‘…2
    )
    ğ‘…2ì— ëŒ€í•œ ì˜¤í•´
    â€¢ ë‹¨ìˆœì„ í˜•íšŒê·€ì—ì„œë§Œ ğ‘…2ì™€ í‘œë³¸ ìƒê´€ê³„ìˆ˜ ğ‘Ÿì´ ê°™ìŒ.
    ğ‘Ÿğ‘¥ğ‘¦ =
    1
    ğ‘› âˆ’ 1
    ğ‘›
    âˆ‘
    ğ‘–=1
    (
    ğ‘¥ğ‘– âˆ’ Ì„ğ‘¥
    ğ‘ ğ‘¥
    ) (ğ‘¦ğ‘– âˆ’ Ì„ğ‘¦
    ğ‘ ğ‘¦
    )
    â€¢ ğ‘…2 ê°’ë§Œì„ ê°€ì§€ê³  íŒë‹¨í•  ìˆ˜ ì—†ëŠ” ì´ìœ  (ì”ì°¨ ê·¸ë˜í”„)
    â€¢ ğ‘…2 ê°’ì€ ì„ í˜•ì ì¸ ëª¨ë¸ì´ ë°ì´í„° ë³€ë™ì„±ì— ëŒ€í•˜ì—¬ ì–¼ë§ˆë‚˜ ì„¤ëª…ë ¥ì„ ê°€ì§€ê³  ìˆëŠ”ê°€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
    â€¢ ğ‘…2 ê°’ì´ ë†’ë‹¤ëŠ” ê²ƒì´ í•­ìƒ íšŒê·€ë¶„ì„ ëª¨ë¸ì´ ë°ì´í„°ì— ì˜ ì í•© (fitting) ë˜ì–´ ìˆë‹¤ëŠ” ì˜ë¯¸ê°€
    ì•„ë‹ˆë‹¤.
    íšŒê·€ëª¨ë¸ ì¡ìŒì˜ ë¶„ì‚° (Regression standard error)
    ë‹¤ìŒ ì¤‘ ì–´ëŠ íšŒê·€ ì§ì„ ì˜ ì˜ˆì¸¡ê°’ì´ ë” ì •í™•í• ê¹Œ?
    â€¢ ì¡ìŒì„ ë°œìƒì‹œí‚¤ëŠ” ë¶„í¬ì˜ ë¶„ì‚° (ğœ
    2
    )ì„ ë‹¤ìŒì˜ ê°’ì„ í†µí•˜ì—¬ ì¶”ì •í•œë‹¤.
    Ì‚ğœ
    2 = ğ‘€ğ‘†ğ¸ = âˆ‘ (ğ‘¦ğ‘– âˆ’ Ì‚ğ‘¦ğ‘–
    )
    2
    ğ‘› âˆ’ ğ‘ âˆ’ 1
    144 | íšŒê·€ë¶„ì„ì˜ ì´í•´
    7
    7.3 ë‹¤ì¤‘ ì„ í˜•íšŒê·€ (Multiple linear regression)
    ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¶„ì„ì—ì„œ ë…ë¦½ë³€ìˆ˜ì˜ ìˆ«ìê°€ ğ‘ê°œë¡œ ëŠ˜ì–´ë‚œ ëª¨í˜•ì´ë‹¤.
    â€¢ ê¸°ë³¸ ê°€ì •ì€ ë™ì¼í•¨.
    ğ‘¦ğ‘– = ğ›½0 + ğ›½1ğ‘¥ğ‘–1 + ... + ğ›½ğ‘ğ‘¥ğ‘–ğ‘ + ğ‘’ğ‘–
    , ğ‘– = 1, ..., ğ‘›
    ìœ„ì˜ í˜•íƒœë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë²¡í„° í˜•íƒœë¡œ í‘œí˜„ í•  ìˆ˜ ìˆìŒ.
    ğ‘¦ğ‘– = x
    ğ‘‡
    ğ‘– ğ›½ + ğ‘’ğ‘–
    , ğ‘– = 1, ..., ğ‘›
    ğ‘‹ =
    â¡
    â¢
    â¢
    â£
    1 ğ‘¥11 â€¦ ğ‘¥1ğ‘
    1 ğ‘¥21 â€¦ ğ‘¥2ğ‘
    â‹® â‹® â‹® â‹®
    1 ğ‘¥ğ‘›1 â€¦ ğ‘¥ğ‘›ğ‘
    â¤
    â¥
    â¥
    â¦
    ğ›½ = â›âœâœ
    â
    ğ›½1
    ...
    ğ›½ğ‘
    ââŸâŸ
    â 
    ë‹¤ì¤‘ ì„ í˜•íšŒê·€ (Multiple linear regression) | 145
    Rì—ì„œ ë‹¤ì¤‘íšŒê·€ë¶„ì„ ì‹¤í–‰í•˜ê¸°
    ê½ƒìì˜ ê¸¸ì´ë¥¼ ì„¸ê°€ì§€ ë…ë¦½ë³€ìˆ˜ë“¤ (ê½ƒì ë„ˆë¹„, ê½ƒë°›ì¹¨ ê¸¸ì´ì™€ ë„ˆë¹„)ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ëª…í•˜ëŠ” íšŒê·€ë¶„ì„
    ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì.
    model2 = ols("Petal_Length ~ Petal_Width + Sepal_Length + Sepal_Width",
    data=iris).fit()
    model2.summary()
    ^à¼ˆ <class 'statsmodels.iolib.summary.Summary'>
    ^à¼ˆ ""
    ^à¼ˆ OLS Regression Results
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Dep. Variable: Petal_Length Rà¼¡squared: 0.968
    ^à¼ˆ Model: OLS Adj. Rà¼¡squared: 0.967
    ^à¼ˆ Method: Least Squares Fà¼¡statistic: 1473.
    ^à¼ˆ Date: í† , 28 10 2023 Prob (Fà¼¡statistic): 6.98e-109
    ^à¼ˆ Time: 14:01:33 Log-Likelihood: -39.408
    ^à¼ˆ No. Observations: 150 AIC: 86.82
    ^à¼ˆ Df Residuals: 146 BIC: 98.86
    ^à¼ˆ Df Model: 3
    ^à¼ˆ Covariance Type: nonrobust
    ^à¼ˆ ================================================================================
    ^à¼ˆ coef std err t P>|t| [0.025 0.975]
    ^à¼ˆ --------------------------------------------------------------------------------
    ^à¼ˆ Intercept -0.2627 0.297 -0.883 0.379 -0.850 0.325
    ^à¼ˆ Petal_Width 1.4468 0.068 21.399 0.000 1.313 1.580
    ^à¼ˆ Sepal_Length 0.7291 0.058 12.502 0.000 0.614 0.844
    ^à¼ˆ Sepal_Width -0.6460 0.068 -9.431 0.000 -0.781 -0.511
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Omnibus: 2.520 Durbin-Watson: 1.783
    ^à¼ˆ Prob(Omnibus): 0.284 Jarque-Bera (JB): 2.391
    ^à¼ˆ Skew: 0.073 Prob(JB): 0.303
    ^à¼ˆ Kurtosis: 3.601 Cond. No. 79.3
    ^à¼ˆ ==============================================================================
    ^à¼ˆ
    ^à¼ˆ Notes:
    ^à¼ˆ [1] Standard Errors assume that the covariance matrix of the errors is correctly â†©
    specified.
    ^à¼ˆ ""
    146 | íšŒê·€ë¶„ì„ì˜ ì´í•´
    7
    ëª¨ë¸ ë¹„êµí•˜ê¸° â€‘ Model 1 vs. Model 2
    ë…ë¦½ë³€ìˆ˜ 2ê°œ ì¶”ê°€ íš¨ìš©ì„±ì´ ìˆëŠ”ì§€ë¥¼ ê²€ì •í•´ë³´ì.
    â€¢ ëª¨ë¸ 1: ë…ë¦½ë³€ìˆ˜ 1ê°œ â€‘ Petal.Width
    â€¢ ëª¨ë¸ 2: ë…ë¦½ë³€ìˆ˜ 3ê°œ â€‘ Petal.Width + Sepal.Length + Sepal.Width
    ê·€ë¬´ê°€ì„¤ vs. ëŒ€ë¦½ê°€ì„¤
    ğ»0
    : Reduced Modelì´ ì•Œë§ìŒ.
    ğ»ğ´: Full Modelì´ ì•Œë§ìŒ.
    Full model vs. Reduced model
    â€¢ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆëŠ” ëª¨ë¸ ì¤‘ í•œ ëª¨ë¸ì´ ë‹¤ë¥¸ ëª¨ë¸ì„ í¬í•¨í•˜ëŠ” í˜•ì‹ì˜ 2 ëª¨ë¸ì„ ë¹„êµ
    â€“ Full model: Petal.Width + Sepal.Length + Sepal.Width
    â€“ Reduced model: Petal.Width
    Fâ€‘ê²€ì •
    â€¢ ë‘ ëª¨ë¸ì˜ ì˜¤ì°¨ì œê³±í•© ì°¨ì´ë¥¼ ë¹„êµ
    ğ¹ = [(ğ‘†ğ‘†ğ¸ (ğ‘…ğ‘€)) âˆ’ ğ‘†ğ‘†ğ¸ (ğ¹ğ‘€)] / (ğ‘ + 1 âˆ’ ğ‘˜)
    ğ‘†ğ‘†ğ¸ (ğ¹ğ‘€) / (ğ‘› âˆ’ ğ‘ âˆ’ 1) âˆ¼ ğ¹(ğ‘+1âˆ’ğ‘˜,ğ‘›âˆ’ğ‘âˆ’1)
    â€¢ Full ëª¨ë¸ì˜ ë…ë¦½ë³€ìˆ˜ ê°¯ìˆ˜ ğ‘
    â€¢ Reduced ëª¨ë¸ì˜ ëª¨ìˆ˜ ê°¯ìˆ˜ (Intercept í¬í•¨) ğ‘˜
    # íŒŒì´ì¬ ì½”ë“œ
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    model1 = ols('Petal_Length ~ Petal_Width', data=iris).fit() #mod1
    model2 = ols('Petal_Length ~ Petal_Width + Sepal_Length + Sepal_Width',
    data=iris).fit() #mod2
    table = sm.stats.anova_lm(model1, model2) #anova
    print(table)
    ^à¼ˆ df_resid ssr df_diff ss_diff F Pr(>F)
    ^à¼ˆ 0 148.0 33.844753 0.0 NaN NaN NaN
    ^à¼ˆ 1 146.0 14.852948 2.0 18.991805 93.341859 7.752746e-27
    F ê²€ì • í†µê³„ëŸ‰ê³¼ pâ€‘valueë¡œ ë¯¸ë£¨ì–´ë³´ì•„ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•  ìˆ˜ ìˆìœ¼ë©°, Full modelì„ ì„ íƒí•  ìˆ˜
    ìˆìŒ.
    ë‹¤ì¤‘ ì„ í˜•íšŒê·€ (Multiple linear regression) | 147
    model2.summary()
    ^à¼ˆ <class 'statsmodels.iolib.summary.Summary'>
    ^à¼ˆ ""
    ^à¼ˆ OLS Regression Results
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Dep. Variable: Petal_Length Rà¼¡squared: 0.968
    ^à¼ˆ Model: OLS Adj. Rà¼¡squared: 0.967
    ^à¼ˆ Method: Least Squares Fà¼¡statistic: 1473.
    ^à¼ˆ Date: í† , 28 10 2023 Prob (Fà¼¡statistic): 6.98e-109
    ^à¼ˆ Time: 14:01:35 Log-Likelihood: -39.408
    ^à¼ˆ No. Observations: 150 AIC: 86.82
    ^à¼ˆ Df Residuals: 146 BIC: 98.86
    ^à¼ˆ Df Model: 3
    ^à¼ˆ Covariance Type: nonrobust
    ^à¼ˆ ================================================================================
    ^à¼ˆ coef std err t P>|t| [0.025 0.975]
    ^à¼ˆ --------------------------------------------------------------------------------
    ^à¼ˆ Intercept -0.2627 0.297 -0.883 0.379 -0.850 0.325
    ^à¼ˆ Petal_Width 1.4468 0.068 21.399 0.000 1.313 1.580
    ^à¼ˆ Sepal_Length 0.7291 0.058 12.502 0.000 0.614 0.844
    ^à¼ˆ Sepal_Width -0.6460 0.068 -9.431 0.000 -0.781 -0.511
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Omnibus: 2.520 Durbin-Watson: 1.783
    ^à¼ˆ Prob(Omnibus): 0.284 Jarque-Bera (JB): 2.391
    ^à¼ˆ Skew: 0.073 Prob(JB): 0.303
    ^à¼ˆ Kurtosis: 3.601 Cond. No. 79.3
    ^à¼ˆ ==============================================================================
    ^à¼ˆ
    ^à¼ˆ Notes:
    ^à¼ˆ [1] Standard Errors assume that the covariance matrix of the errors is correctly â†©
    specified.
    ^à¼ˆ ""
    ê° ë…ë¦½ë³€ìˆ˜ë“¤ì˜ ê³„ìˆ˜ë“¤ì´ 0ì´ ì•„ë‹Œ ê°’ì„ ê°–ëŠ” ê²ƒì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤ê³  íŒë‹¨í•  ìˆ˜ ìˆìŒ.
    ëª¨ë¸ ì§„ë‹¨í•˜ê¸°
    1ë³€ìˆ˜ ê·¸ë˜í”„: Histogram, Box plot
    ì£¼ìš” ì²´í¬ ì‚¬í•­ â€‘ ê° ë³€ìˆ˜ë“¤ ì¤‘ skewí•œ ë¶„í¬ê°€ ì—†ëŠ”ì§€ í™•ì¸
    148 | íšŒê·€ë¶„ì„ì˜ ì´í•´
    7
    2ë³€ìˆ˜ ê·¸ë˜í”„: Correlation plot
    # íŒŒì´ì¬ ì½”ë“œ
    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    cols = ["Petal_Length", "Sepal_Length", "Sepal_Width", "Petal_Width"]
    corr_mat = iris[cols].corr().round(2)
    sns.heatmap(corr_mat, annot=True, cmap=plt.cm.Reds);
    plt.show()
    Petal_Length Sepal_Length Sepal_Width Petal_Width
    Petal_Length
    Sepal_Length
    Sepal_Width
    Petal_Width
    1 0.87 -0.43 0.96
    0.87 1 -0.12 0.82
    -0.43 -0.12 1 -0.37
    0.96 0.82 -0.37 1
    0.4
    0.2
    0.0
    0.2
    0.4
    0.6
    0.8
    1.0
    ì”ì°¨ ê·¸ë˜í”„ì™€ ê²€ì •
    ì”ì°¨ì˜ ì •ê·œì„±ê³¼ ì”ì°¨ì˜ ë“±ë¶„ì‚°ì„± ì²´í¬
    â€¢ ì •ê·œì„±
    â€“ Andersonâ€‘Darling Test í˜¹ì€ Shapiroâ€‘Wilk Testë¥¼ ì‹¤ì‹œí•œë‹¤.
    â€¢ ì”ì°¨ ë“±ë¶„ì‚°ì„± ê²€ì •
    â€“ ì–´ë–»ê²Œ ì²´í¬í• ê¹Œ? F test, Bartlett ê²€ì • í˜¹ì€ Levene ê²€ì •?
    â€“ ì”ì°¨ë¥¼ ê·¸ë£¹ì„ ë‚˜ëˆ ì„œ ì²´í¬ í•  ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì¡´ì¬í•˜ì§€ ì•ŠìŒ.
    # íŒŒì´ì¬ ì½”ë“œ
    import scipy.stats as stats
    residuals = model2.resid
    fitted_values = model2.fittedvalues
    ë‹¤ì¤‘ ì„ í˜•íšŒê·€ (Multiple linear regression) | 149
    plt.figure(figsize=(15,4))
    ^à¼ˆ <Figure size 1500x400 with 0 Axes>
    plt.subplot(1,2,1)
    ^à¼ˆ <AxesSubplot:>
    plt.scatter(fitted_values, residuals);
    plt.subplot(1,2,2)
    ^à¼ˆ <AxesSubplot:>
    stats.probplot(residuals, plot=plt);
    plt.show()
    1 2 3 4 5 6 7
    1.0
    0.5
    0.0
    0.5
    1.0
    2 1 0 1 2
    Theoretical quantiles
    1.0
    0.5
    0.0
    0.5
    1.0
    Ordered Values
    Probability Plot
    Breuschâ€“Pagan / Cookâ€“Weisberg ê²€ì •
    â€¢ ì•„ì´ë””ì–´: ìš°ë¦¬ì˜ ì”ì°¨ê°€ ë“±ë¶„ì‚°ì„ ê°–ëŠ”ë‹¤ëŠ” ì˜ë¯¸ëŠ” ë…ë¦½ë³€ìˆ˜ì— ì˜í•˜ì—¬ ì„¤ëª…ì´ ì•ˆëœë‹¤ëŠ” ì˜ë¯¸
    â€¢ Breuschâ€“Pagan ì„ í˜•ì„±
    â€“ ğ»0
    : ëª¨ë“  ê³„ìˆ˜ 0
    â€“ ğ»ğ´: 0ì´ ì•„ë‹Œ ê³„ìˆ˜ ì¡´ì¬
    ê·€ë¬´ê°€ì„¤ í•˜ì—ì„œ ê²€ì •í†µê³„ëŸ‰ì€ ì¹´ì´ì œê³±ë¶„í¬ ğ‘ë¥¼ ë”°ë¦„.
    Ì‚ğ‘Ÿ
    2
    ğ‘–
    / Ì‚ğœ2 = ğ›¿0 + ğ›¿1ğ‘‹1 + ... + ğ›¿ğ‘ğ‘‹ğ‘ + ğ‘›ğ‘œğ‘–ğ‘ ğ‘’
    from statsmodels.stats.diagnostic import het_breuschpagan
    model = ols('Petal_Length ~ Petal_Width + Sepal_Length + Sepal_Width', data=iris).fit()
    bptest = het_breuschpagan(model.resid, model.model.exog)
    print('BPà¼¡test statistics: ', bptest[0])
    ^à¼ˆ BPà¼¡test statistics: 6.039114919618932
    150 | íšŒê·€ë¶„ì„ì˜ ì´í•´
    7
    print('pà¼¡value: ', bptest[1])
    ^à¼ˆ pà¼¡value: 0.10972262962330982
    ì˜¤ì°¨ ë…ë¦½ì„±
    íŠ¹ì • íŒ¨í„´ì„ ë„ì§€ ì•ŠëŠ”ì§€, ë¶„ì‚°ì´ ë³€í•˜ì§€ëŠ” ì•ŠëŠ”ì§€ë¥¼ ì²´í¬í•œë‹¤.
    â€¢ Durbinâ€‘Watson test ì‹¤ì‹œ
    â€“ ê·€ë¬´ê°€ì„¤: ì”ì°¨ë“¤ê°„ì˜ ìƒê´€ì„±ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
    â€“ ëŒ€ë¦½ê°€ì„¤: ì”ì°¨ë“¤ê°„ì˜ ìê¸° ìƒê´€ì„±ì´ ì¡´ì¬í•œë‹¤.
    ê·¸ë¦¼ 7.1: (ì™¼ìª½) ë¹„ì„ í˜•ì„±ì„ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ëª¨í˜•ì„ ê³ ë ¤ vs. (ì˜¤ë¥¸ìª½) ë“±ë¶„ì‚°ì„±ì„ ë§Œì¡±í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°
    from statsmodels.stats.stattools import durbin_watson
    dw_stat = durbin_watson(model2.resid)
    print(dw_stat)
    ^à¼ˆ 1.782966528592163
    7.4 ì—°ìŠµë¬¸ì œ
    palmerpenguins íŒ¨í‚¤ì§€ì—ëŠ” ë‚¨ê·¹ Palmer stationì—ì„œ ê´€ì¸¡í•œ í­ê·„ ì •ë³´ë“¤ì´ í¬í•¨ëœ ë°ì´í„°ì´ë‹¤.
    import pandas as pd
    import numpy as np
    from palmerpenguins import load_penguins
    penguins = load_penguins()
    print(penguins.head())
    ì—°ìŠµë¬¸ì œ | 151
    ^à¼ˆ species island bill_length_mm ^^. body_mass_g sex year
    ^à¼ˆ 0 Adelie Torgersen 39.1 ^^. 3750.0 male 2007
    ^à¼ˆ 1 Adelie Torgersen 39.5 ^^. 3800.0 female 2007
    ^à¼ˆ 2 Adelie Torgersen 40.3 ^^. 3250.0 female 2007
    ^à¼ˆ 3 Adelie Torgersen NaN ^^. NaN NaN 2007
    ^à¼ˆ 4 Adelie Torgersen 36.7 ^^. 3450.0 female 2007
    ^à¼ˆ
    ^à¼ˆ [5 rows x 8 columns]
    np.random.seed(2022)
    train_index = np.random.choice(penguins.shape[0], 200)
    1) train_index ë¥¼ ì‚¬ìš©í•˜ì—¬ í­ê·„ ë°ì´í„°ì—ì„œ ì¸ë±ìŠ¤ì— ëŒ€ì‘í•˜ëŠ” í‘œë³¸ë“¤ì„ ë½‘ì•„ì„œ train_dataë¥¼
    ë§Œë“œì„¸ìš”. (ë‹¨, ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ê²½ìš° ì œê±°)
    2) train_dataì˜ í­ê·„ ë¶€ë¦¬ê¸¸ì´ (bill_length_mm)ë¥¼ ë¶€ë¦¬ ê¹Šì´ (bill_depth_mm)ë¥¼ ì‚¬ìš©í•˜ì—¬
    ì‚°ì ë„ë¥¼ ê·¸ë ¤ë³´ì„¸ìš”.
    3) í­ê·„ ë¶€ë¦¬ê¸¸ì´ (bill_length_mm)ë¥¼ ë¶€ë¦¬ ê¹Šì´ (bill_depth_mm)ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ êµ¬í•˜ê³ , ë‘
    ë³€ìˆ˜ ì‚¬ì´ì— ìœ ì˜ë¯¸í•œ ìƒê´€ì„±ì´ ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì •í•´ë³´ì„¸ìš”.
    4) í­ê·„ ë¶€ë¦¬ê¸¸ì´ (bill_length_mm)ë¥¼ ë¶€ë¦¬ ê¹Šì´ (bill_depth_mm)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ëª…í•˜ëŠ” íšŒê·€
    ëª¨ë¸ì„ ì í•©ì‹œí‚¨ í›„ 2ë²ˆì˜ ì‚°ì ë„ì— íšŒê·€ ì§ì„ ì„ ë‚˜íƒ€ë‚´ ë³´ì„¸ìš”. (ëª¨ë¸ 1)
    5) ì í•©ëœ íšŒê·€ ëª¨ë¸ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œì§€ íŒë‹¨í•´ë³´ì„¸ìš”.
    6) ğ‘…2 ê°’ì„ êµ¬í•œ í›„ ì˜ë¯¸ë¥¼ í•´ì„í•´ ë³´ì„¸ìš”.
    7) ì í•©ëœ íšŒê·€ ëª¨ë¸ì˜ ê³„ìˆ˜ë¥¼ í•´ì„í•´ ë³´ì„¸ìš”.
    8) 1ë²ˆì—ì„œ ì í•©í•œ íšŒê·€ ëª¨ë¸ì— ìƒˆë¡œìš´ ë³€ìˆ˜ (ì¢… â€‘ species) ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì„±ë³„ ë³€ìˆ˜
    ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì  ìƒ‰ê¹”ì„ ë‹¤ë¥´ê²Œ ì‹œê°í™” í•œ í›„ ì í•©ëœ ëª¨ë¸ì˜ íšŒê·€ ì§ì„ ì„ ì‹œê°í™” í•´ë³´ì„¸ìš”.
    (ëª¨ë¸ 2)
    9) ì¢… ë³€ìˆ˜ê°€ ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë¸ 2ê°€ ëª¨ë¸ 1 ë³´ë‹¤ ë” ì¢‹ì€ ëª¨ë¸ì´ë¼ëŠ” ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.
    10) ëª¨ë¸ 2ì˜ ê³„ìˆ˜ì— ëŒ€í•œ ê²€ì •ê³¼ ê·¸ ì˜ë¯¸ë¥¼ í•´ì„í•´ ë³´ì„¸ìš”.
    11) ëª¨ë¸ 2 ì— ì”ì°¨ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê³ , íšŒê·€ëª¨ë¸ ê°€ì •ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì¦ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
    12) ëª¨ë¸ 2 ì˜ ì”ì°¨ë¥¼ í†µí•˜ì—¬ ì˜í–¥ì , í˜¹ì€ ì´ìƒì¹˜ì˜ ìœ ë¬´ë¥¼ íŒë‹¨í•´ë³´ì„¸ìš”.
    """