def s11_2():
    """
    Chapter 4. ë¹„ëª¨ìˆ˜ ê²€ì • ì¹œí•´ì§€ê¸°
    ë¬¸ì œ 1. ì‹ ì œí’ˆ ì´‰ë§¤ì œ
    ìŠ¬í†µ íšŒì‚¬ì—ì„œëŠ” ì´ë²ˆì— ì¶œì‹œí•œ ìƒˆë¡œìš´ ì´‰ë§¤ì œì˜ íš¨ëŠ¥ì„ ê²€ì¦í•˜ê³  ì‹¶ì–´í•œë‹¤. ì‹ ì œí’ˆ ì´‰ë§¤ì¬ëŠ” ê¸°ì¡´
    ê³µì •ì—ì„œ ì‚¬ìš©ë˜ëŠ” í™”í•™ë°˜ì‘ ì†ë„ë¥¼ í˜ì‹ ì ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” ê¸°ëŠ¥ì´ íƒ‘ì¬ë˜ì–´ ìˆë‹¤ê³  í•œë‹¤.
    íšŒì‚¬ ì œí’ˆ ê²€ì¦ ë¶€ì„œì—ì„œëŠ” ê¸°ì¡´ ê³µì •ì˜ í™”í•™ ë°˜ì‘ì†ë„ì™€ ì´‰ë§¤ì œë¥¼ ë„£ì€ í›„ì˜ ë°˜ì‘ ì†ë„ë¥¼ ì¸¡ì •í•˜ì—¬
    í‘œ 4.4 ë°ì´í„°ë¥¼ ë§Œë“¤ì—ˆë‹¤.
    1. ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ì‹ ì œí’ˆ ì´‰ë§¤ì œê°€ ê¸°ì¡´ì˜ í™”í•™ ê³µì •ì„ ë‹¨ì¶•ì‹œí‚¨ë‹¤ê³  í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•˜ì—¬
    ê²€ì •í•˜ì‹œì˜¤.
    2. ì´‰ë§¤ì œë¡œ ì¸í•œ ë‹¨ì¶•ëœ ê³µì • ì‹œê°„ì— ëŒ€í•˜ì—¬ 90% ì‹ ë¢°êµ¬ê°„ì„ êµ¬í•˜ì‹œì˜¤.
    import pandas as pd
    import numpy as np
    # íŒŒì´ì¬ ì½”ë“œ
    time = [2.17, 0.86, 0.91, 3.11, 1.29, 1.25, 0.76, 2.98, 1.21,
    2.23, 0.67, 1.22, 1.23, 1.21, 1.71, 1.80, 1.41, 1.01,
    0.82, 1.03, 2.03, 0.65, 1.01, 0.45, 0.98, 1.04]
    treat = ['before']*13 + ['add_catalyst']*13
    id = list(range(1,27))
    prac4_1 = pd.DataFrame({'ID':id,
    'Time':time,
    'treat':treat})
    prac4_1.head()
    ^à¼ˆ ID Time treat
    ^à¼ˆ 0 1 2.17 before
    ^à¼ˆ 1 2 0.86 before
    ^à¼ˆ 2 3 0.91 before
    ^à¼ˆ 3 4 3.11 before
    ^à¼ˆ 4 5 1.29 before
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 227
    í‘œ 11.4: ì´‰ë§¤ì œ ì„±ëŠ¥ ë¹„êµ ë°ì´í„°
    ID Time Treat
    1 2.17 before
    2 0.86 before
    3 0.91 before
    4 3.11 before
    5 1.29 before
    6 1.25 before
    7 0.76 before
    8 2.98 before
    9 1.21 before
    10 2.23 before
    11 0.67 before
    12 1.22 before
    13 1.23 before
    14 1.21 add_catalyst
    15 1.71 add_catalyst
    16 1.80 add_catalyst
    17 1.41 add_catalyst
    18 1.01 add_catalyst
    19 0.82 add_catalyst
    20 1.03 add_catalyst
    21 2.03 add_catalyst
    22 0.65 add_catalyst
    23 1.01 add_catalyst
    24 0.45 add_catalyst
    25 0.98 add_catalyst
    26 1.04 add_catalyst
    ê°€ì„¤ ì„¤ì •
    â€¢ ğ»0
    : ì‹ ì œí’ˆ ì´‰ë§¤ì œëŠ” í™”í•™ ê³µì • ì‹œê°„ì„ ë‹¨ì¶•ì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤.
    â€“ ğœ‡ğ‘ğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’ â‰¤ ğœ‡ğ‘ğ‘ğ‘¡ğ‘ğ‘™ğ‘¦ğ‘ ğ‘¡
    â€¢ ğ»ğ´: ì‹ ì œí’ˆ ì´‰ë§¤ì œëŠ” í™”í•™ ê³µì • ì‹œê°„ì„ ë‹¨ì¶•ì‹œí‚¨ë‹¤.
    â€“ ğœ‡ğ‘ğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’ > ğœ‡ğ‘ğ‘ğ‘¡ğ‘ğ‘™ğ‘¦ğ‘ ğ‘¡
    ì •ê·œì„± ê²€ì •
    ê° ê·¸ë£¹ì— ëŒ€í•œ ì •ê·œì„± ê²€ì •ì„ ì‹œê°í™” ê¸°ë²•ê³¼ Shapiroâ€‘wilk ê²€ì •ì„ ì‚¬ìš©í•˜ì—¬ ì‹œí–‰í•œë‹¤.
    before = prac4_1[prac4_1['treat']^à¼°'before']
    add_catalyst = prac4_1[prac4_1['treat']^à¼°'add_catalyst']
    import pingouin as pg
    import matplotlib.pyplot as plt
    228 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    plt.subplot(1,2,1)
    ^à¼ˆ <AxesSubplot:>
    ax = pg.qqplot(before['Time'], dist='norm')
    plt.subplot(1,2,2)
    ^à¼ˆ <AxesSubplot:>
    ax = pg.qqplot(add_catalyst['Time'], dist='norm')
    plt.ylim(-3, 3);
    plt.xlim(-3, 3);
    plt.show()
    0 2
    Theoretical quantiles
    1
    0
    1
    2
    Ordered quantiles
    R
    2 = 0.849
    2 0 2
    Theoretical quantiles
    2
    0
    2
    Ordered quantiles
    R
    2 = 0.943
    ë‘ ê·¸ë£¹ì˜ QQ plotì„ íŒë‹¨í•´ ë³´ì•˜ì„ ë•Œ, ì‹ ë¢°êµ¬ê°„ ì•ˆì— ëª¨ë“  ë°ì´í„°ê°€ ë“¤ì–´ìˆìœ¼ë‚˜ ê°€ìš´ë° ë¶€ë¶„ì—ì„œ
    ë‘ ê·¸ë£¹ ëª¨ë‘ ê¸°ì¤€ì„ ì„ ë²—ì–´ë‚˜ëŠ” ê²½í–¥ì„±ì„ ë³´ì¸ë‹¤. ì¢€ ë” ì •í™•í•œ ê²€ì •ì„ ìœ„í•˜ì—¬ ìœ ì˜ìˆ˜ì¤€ 5% í•˜ì—ì„œ
    Shapiroâ€‘Wilk ê²€ì •ì„ ì‹œí–‰í•œë‹¤.
    â€¢ Shapiroâ€‘Wilk ê²€ì •ì˜ ê·€ë¬´ê°€ì„¤ê³¼ ëŒ€ë¦½ê°€ì„¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
    â€“ ê·€ë¬´ê°€ì„¤: ë°ì´í„°ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤.
    â€“ ëŒ€ë¦½ê°€ì„¤: ë°ì´í„°ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠëŠ”ë‹¤.
    from scipy.stats import shapiro
    shapiro(before['Time'])
    ^à¼ˆ ShapiroResult(statistic=0.8367362022399902, pvalue=0.019262485206127167)
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 229
    shapiro(add_catalyst['Time'])
    ^à¼ˆ ShapiroResult(statistic=0.941055178642273, pvalue=0.4707110524177551)
    ë‘ ê·¸ë£¹ ì¤‘ before ê·¸ë£¹ì— ëŒ€ì‘í•˜ëŠ” pâ€‘value ê°’ 0.01926ì´ ìœ ì˜ìˆ˜ì¤€ì¸ 5%ë³´ë‹¤ ì‘ìœ¼ë¯€ë¡œ ê·€ë¬´ê°€ì„¤
    ì„ ê¸°ê°í•œë‹¤. ë”°ë¼ì„œ ë°ì´í„°ê°€ ì •ê·œì„±ì„ ë”°ë¥¸ë‹¤ê³  íŒë‹¨í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ë¹„ëª¨ìˆ˜ ê²€ì •ì„ ì§„í–‰í•˜ë„ë¡ í•œë‹¤.
    ë”°ë¼ì„œ, ì•ì—ì„œ ì„¤ì •í•œ ê·€ë¬´ê°€ì„¤, ëŒ€ë¦½ê°€ì„¤ì˜ ëª¨ìˆ˜ê°€ ëª¨ë¶„í¬ì˜ ì¤‘ì•™ê°’ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì— ì£¼ì˜í•˜ì.
    ë“±ë¶„ì‚°ì„± ê²€ì • ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ë‘ ê·¸ë£¹ ë°ì´í„°ì˜ ë“±ë¶„ì‚°ì„± ê°€ì •ì„ Leveneâ€™s testë¥¼ í†µí•˜ì—¬ í™•
    ì¸í•œë‹¤.
    plt.subplot(1,2,1)
    ^à¼ˆ <AxesSubplot:>
    plt.hist(before['Time'], bins=30);
    plt.subplot(1,2,2)
    ^à¼ˆ <AxesSubplot:>
    plt.hist(add_catalyst['Time'],bins=30);
    plt.show();
    1 2 3
    0
    1
    2
    3
    1 2
    0
    1
    2
    3
    before ê·¸ë£¹ì˜ íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ íŒë‹¨í–ˆì„ë•Œ ì •ê·œì„±ì´ ë³´ì¥ë˜ì§€ ì•ŠëŠ” ë°ì´í„°ì´ë©°, ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì‚´ì§
    ì¹˜ìš°ì³ìˆëŠ” ë°ì´í„° ì´ë¯€ë¡œ, ì¢€ ë” robustí•œ ê²€ì •ì„ ìœ„í•˜ì—¬ center ì˜µì…˜ì€ medianìœ¼ë¡œ ì„¤ì •í•œ í›„ ì§„í–‰
    í•˜ì˜€ë‹¤.
    â€¢ ê·€ë¬´ê°€ì„¤: ë‘ ê·¸ë£¹ì˜ ëª¨ë¶„ì‚°ì´ ê°™ë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤: ë‘ ê·¸ë£¹ì˜ ëª¨ë¶„ì‚°ì€ ê°™ì§€ ì•Šë‹¤.
    230 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    from scipy.stats import levene
    a = before['Time']
    b = add_catalyst['Time']
    levene(b, a, center='median')
    ^à¼ˆ LeveneResult(statistic=1.404486168289024, pvalue=0.24757651251351717)
    ê²€ì •ì˜ pâ€‘valueê°’ 0.2476ì´ ìœ ì˜ìˆ˜ì¤€ì¸ 5% ë³´ë‹¤ í¬ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì§€ ëª»í•œë‹¤. ë”°ë¼ì„œ ë‘
    ê·¸ë£¹ ë°ì´í„°ëŠ” ë“±ë¶„ì‚° ê°€ì •ì„ ë§Œì¡±í•œë‹¤ê³  íŒë‹¨í•˜ì˜€ë‹¤.
    ìœ„ì™€ ê°™ì€ ì´ìœ ë¡œ, ê°€ì¥ ì í•©í•œ ê²€ì •ì€ Mannâ€‘Whitneyâ€‘Wilcoxon U testë¡œ íŒë‹¨í•˜ì—¬ ê²€ì •ì„ ì§„
    í–‰í•œë‹¤.
    â€¢ ğ»0
    : ì‹ ì œí’ˆ ì´‰ë§¤ì œëŠ” í™”í•™ ê³µì • ì‹œê°„ì„ ë‹¨ì¶•ì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤.
    â€“ ğœ‚ğ‘ğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’ = ğœ‚ğ‘ğ‘ğ‘¡ğ‘ğ‘™ğ‘¦ğ‘ ğ‘¡
    â€¢ ğ»ğ´: ì‹ ì œí’ˆ ì´‰ë§¤ì œëŠ” í™”í•™ ê³µì • ì‹œê°„ì„ ë‹¨ì¶•ì‹œí‚¨ë‹¤.
    â€“ ğœ‚ğ‘ğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’ > ğœ‚ğ‘ğ‘ğ‘¡ğ‘ğ‘™ğ‘¦ğ‘ ğ‘¡
    from scipy.stats import mannwhitneyu
    mannwhitneyu(before['Time'],add_catalyst['Time'], alternative='greater')
    ^à¼ˆ MannwhitneyuResult(statistic=106.5, pvalue=0.1350263415415442)
    ê²€ì •ì— ëŒ€ì‘í•˜ëŠ” pâ€‘value ê°’ 0.135ê°€ ìœ ì˜ìˆ˜ì¤€ 0.05ë³´ë‹¤ í¬ë¯€ë¡œ, ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì§€ ëª»í•œë‹¤.
    ë”°ë¼ì„œ ì‹ ì œí’ˆ ì´‰ë§¤ì œê°€ ê¸°ì¡´ í™”í•™ ê³µì • ì‹œê°„ì„ ë‹¨ì¶• ì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤ê³  íŒë‹¨í•œë‹¤.
    â€¢ ì°¸ê³ : ë°ì´í„°ì— tieê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° mannwhitneyu() í•¨ìˆ˜ëŠ” ì •ê·œê·¼ì‚¬ì— ì˜í•œ ìœ ì˜ í™•ë¥ ì„ ê³„ì‚°
    í•œë‹¤.
    len(prac4_1['Time']) - len(prac4_1["Time"].unique())
    ^à¼ˆ 2
    ì‹ ë¢°êµ¬ê°„
    ë¹„ëª¨ìˆ˜ ê²€ì •ì˜ ì •í™•í•œ ì‹ ë¢°êµ¬ê°„ì„ êµ¬í•˜ëŠ” ê²ƒì€ ìƒë‹¹íˆ ê¹Œë‹¤ë¡­ë‹¤. ë”°ë¼ì„œ ì£¼ì–´ì§„ í‘œë³¸ìœ¼ë¡œ ê°€ëŠ¥í•œ ê°ì†Œ
    ì‹œê°„ì˜ í‘œë³¸ë“¤ì„ ë§Œë“¤ê³ , ì´ë¥¼ í†µí•˜ì—¬ ìœ ì¶”í•˜ë„ë¡ í•œë‹¤.
    # 'before' ê·¸ë£¹ê³¼ 'add_catalyst' ê·¸ë£¹ì˜ score ê°’ì„ ì¶”ì¶œ
    u = prac4_1[prac4_1['treat'] ^à¼° 'before']['Time'].values
    v = prac4_1[prac4_1['treat'] ^à¼° 'add_catalyst']['Time'].values
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 231
    # uì™€ vì˜ ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•© ìƒì„±
    df = pd.DataFrame({'Var1': np.repeat(u, len(v)),
    'Var2': np.tile(v, len(u))})
    # ê° ì¡°í•©ì— ëŒ€í•´ Var1ê³¼ Var2ì˜ ì°¨ì´ ê³„ì‚°
    m = df['Var1'] - df['Var2']
    # mì˜ 5% ë° 95% ë¶„ìœ„ìˆ˜ ê³„ì‚°
    quantiles = m.quantile([0.05, 0.95])
    quantiles
    ^à¼ˆ 0.05 -0.920
    ^à¼ˆ 0.95 2.092
    ^à¼ˆ dtype: float64
    ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ì´‰ë§¤ì œë¡œ ì¸í•œ ê³µì • ì‹œê°„ì˜ ë¶„í¬ ì‹¤ì œ ì¤‘ì•™ê°’ ê°ì†Œ ì‹œê°„ì€ (âˆ’0.920, 2.092) êµ¬ê°„ì—
    ì¡´ì¬í•  ê²ƒì´ë¼ 90% ì‹ ë¢°í•œë‹¤.
    ë¬¸ì œ 2. ì‹¬ì¥ ì§ˆí™˜ ì•½ íš¨ëŠ¥
    ìŠ¬í†µì œì•½ì˜ ì‹ ì•½ì´ ì‹¬ì¥ ì§ˆí™˜ í™˜ìì˜ í˜ˆì••ì„ ë‚®ì¶œ ìˆ˜ ìˆëŠ”ì§€ ê²€ì¦í•˜ë ¤ê³  í•œë‹¤. í‘œë³¸ìœ¼ë¡œ 15ëª…ì˜ í™˜ìê°€
    ì„ íƒë˜ì—ˆìœ¼ë©°, ì•½ì„ ë³µìš©í•˜ê¸° ì „ê³¼ ë³µìš©í•œ í›„ì˜ í˜ˆì••ì„ ì¸¡ì •í•˜ì˜€ë‹¤.
    â€¢ ë³µìš©ì „: 130, 125, 120, 135, 140, 136, 129, 145, 150, 135, 128, 140, 139, 130, 145
    â€¢ ë³µìš©í›„: 125, 120, 115, 130, 135, 134, 128, 140, 145, 134, 127, 140, 138, 129, 142
    ì•½ì´ í˜ˆì••ì„ ì‹¤ì œë¡œ ë‚®ì¶”ëŠ” ê²ƒì¸ì§€ ê²€ì¦í•˜ê¸° ìœ„í•˜ì—¬ ë¶€í˜¸ ê²€ì •ì„ ì‹¤ì‹œí•˜ë¼. ìœ ì˜ ìˆ˜ì¤€ì€ 0.05ë¡œ
    í•˜ê³ , ê²€ì •ì„ ìˆ˜í–‰í•˜ì‹œì˜¤.
    ì˜ˆì‹œ ë‹µì•ˆ
    ë¶€í˜¸ ê²€ì •ì€ ê° ìŒì˜ ì°¨ì´ì— ëŒ€í•´ ë¶€í˜¸ë¥¼ ê²€ì‚¬í•˜ì—¬, ì´ ê²½ìš°ì—ëŠ” ë³µìš© ì „, í›„ì˜ í˜ˆì•• ì°¨ì´ê°€ 0ì¸ì§€
    ì•„ë‹ˆë©´ í˜ˆì••ì´ ë‚®ì•„ì¡ŒëŠ”ì§€(ì „ â€‘ í›„ í˜ˆì•• ì°¨ì´ê°€ 0ë³´ë‹¤ í° ì§€)ë¥¼ ê²€ì‚¬í•˜ê³ ì í•©ë‹ˆë‹¤. ì§„í–‰í•˜ê³ ì í•˜ëŠ”
    ê²€ì •ì˜ ê·€ë¬´ê°€ì„¤ê³¼ ëŒ€ë¦½ê°€ì„¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
    â€¢ ê·€ë¬´ ê°€ì„¤: ì•½ ë³µìš© ì „ê³¼ ë³µìš© í›„ í˜ˆì••ì°¨ ë¶„í¬ì˜ ì¤‘ì•™ê°’ì€ 0ì´ë‹¤.
    â€“ Î” âˆ¶= ğœ‚ğ‘ğ‘ğ‘–ğ‘Ÿ1
    âˆ’ ğœ‚ğ‘ğ‘ğ‘–ğ‘Ÿ2
    = 0
    â€¢ ëŒ€ë¦½ ê°€ì„¤: ì•½ ë³µìš© ì „ê³¼ ë³µìš© í›„ í˜ˆì••ì°¨ ë¶„í¬ì˜ ì¤‘ì•™ê°’ì€ 0ë³´ë‹¤ í¬ë‹¤.
    â€“ Î” > 0
    ë¨¼ì €, ê° í™˜ìì˜ í˜ˆì•• ì°¨ì´(ë³µìš© ì „ â€‘ ë³µìš© í›„)ë¥¼ ê³„ì‚°í•˜ê³ , ì–‘ìˆ˜ì™€ 0ì˜ ê°œìˆ˜ë¥¼ ì„¸ì–´ë³´ê² ìŠµë‹ˆë‹¤.
    from scipy.stats import binom_test
    import numpy as np
    232 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    # ë³µìš© ì „ í›„ì˜ í˜ˆì••
    before_np = np.array([130, 125, 120, 135, 140, 136, 129,
    145, 150, 135, 128, 140, 139, 130, 145])
    after_np = np.array([125, 120, 115, 130, 145, 134, 128,
    140, 145, 134, 127, 140, 140, 129, 142])
    # ì°¨ì´ ê³„ì‚°
    diff = before_np - after_np
    # ì°¨ì´ê°€ 0ë³´ë‹¤ í° ê²½ìš°ë¥¼ ì„¸ê¸° (í˜ˆì••ì´ ë‚®ì•„ì§„ ê²½ìš°)
    successes = sum(diff > 0)
    successes
    ^à¼ˆ 12
    Pythonì—ì„œ ì œê³µí•˜ëŠ” sign_test() í•¨ìˆ˜ì˜ ê²½ìš° ë‹¨ì¸¡ê²€ì • ì˜µì…˜ì„ ì œê³µí•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
    from statsmodels.stats.descriptivestats import sign_test
    # statsmodelsì˜ sign_test í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€í˜¸ ê²€ì • ìˆ˜í–‰
    test_statistic, p_value = sign_test(diff, mu0=0)
    test_statistic, p_value
    ^à¼ˆ (5.0, 0.012939453125)
    binom_test() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¸¡ê²€ì • pâ€‘vlaueë¥¼ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
    # ì´í•­ ê²€ì • ìˆ˜í–‰
    # from scipy.stats import binom
    # 1à¼¡binom.cdf(11, 14, 0.5)
    p_value = binom_test(successes, 14, alternative='greater')
    successes, len(diff[diff ^à»» 0]), p_value
    ^à¼ˆ (12, 14, 0.0064697265625)
    ì´í•­ë¶„í¬ (14, 0.5)ì—ì„œ ê²€ì • í†µê³„ëŸ‰ ê°’ 12ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì€ ê°’ì´ ë‚˜ì˜¬ í™•ë¥ ì€ 0.6%ë¡œ ìœ ì˜ ìˆ˜ì¤€
    5%ë³´ë‹¤ ë‚®ì•„ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•œë‹¤. ë”°ë¼ì„œ ì‹ ì•½ì´ ì‹¬ì¥ ì§ˆí™˜ í™˜ìì˜ í˜ˆì••ì„ ë‚®ì¶œ ìˆ˜ ìˆë‹¤ê³  íŒë‹¨í•œë‹¤.
    Chapter 5. ì¹´ì´ì œê³± ê²€ì • ì¹œí•´ì§€ê¸°
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 233
    ë¬¸ì œ 1. íœ´ëŒ€ì „í™” ì‚¬ìš©ìë“¤ì˜ ì •ì¹˜ ì„±í–¥ì€ ë‹¤ë¥¼ê¹Œ?
    ë‹¤ìŒì€ íœ´ëŒ€ì „í™”ì™€ ìœ ì„ ì „í™”ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ì‚¬ìš©ìë“¤ê³¼ ìœ ì„ ì „í™”ë§Œì„ ì‚¬ìš©í•˜ëŠ” ì‚¬ìš©ìë“¤ì˜ ì •ì¹˜
    ì„±í–¥ì„ ì¡°ì‚¬í•œ ë°ì´í„°ì´ë‹¤. ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ì •ë‹¹ ì§€ì§€ì™€ í•¸ë“œí° ì‚¬ìš© ìœ ë¬´ ì‚¬ì´ì— ìƒê´€ì„±ì„ ê²€ì •
    í•´ë³´ì„¸ìš”.
    í‘œ 11.5: ì •ì¹˜ ì„±í–¥ ì„¤ë¬¸ì¡°ì‚¬ ê²°ê³¼
    ì •ë‹¹ì§€ì§€ í•¸ë“œí° ìœ ì„ ì „í™”
    ì§„ë³´ 49 47
    ì¤‘ë„ 15 27
    ë³´ìˆ˜ 32 30
    ë°ì´í„° ì…ë ¥
    import pandas as pd
    data = [[49,47],[15,27],[32,30]]
    columns = ["í•¸ë“œí°", "ìœ ì„ ì „í™”"]
    index = ["ì§„ë³´", "ì¤‘ë„", "ë³´ìˆ˜"]
    phone_data = pd.DataFrame(data, columns=columns, index=index)
    phone_data
    ^à¼ˆ í•¸ë“œí° ìœ ì„ ì „í™”
    ^à¼ˆ ì§„ë³´ 49 47
    ^à¼ˆ ì¤‘ë„ 15 27
    ^à¼ˆ ë³´ìˆ˜ 32 30
    ê·€ë¬´ê°€ì„¤ vs. ëŒ€ë¦½ê°€ì„¤
    â€¢ ğ»0
    : í•¸ë“œí° ì‚¬ìš© ì—¬ë¶€ì™€ ì •ë‹¹ ì§€ì§€ ì„±í–¥ì€ ë…ë¦½ì´ë‹¤.
    â€¢ ğ»ğ´: í•¸ë“œí° ì‚¬ìš© ì—¬ë¶€ì™€ ì •ë‹¹ ì§€ì§€ ì„±í–¥ì€ ë…ë¦½ì´ ì•„ë‹ˆë‹¤.
    ê¸°ëŒ€ë¹ˆë„ ì²´í¬í•˜ê¸° ë…ë¦½ì„± ê²€ì •ì€ ê° ì…€ì˜ ê¸°ëŒ€ë¹ˆë„ê°€ ëª¨ë‘ 5 ì´ìƒ ë˜ì–´ì•¼ ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆë‹¤.
    ì•„ë˜ì˜ ê²°ê³¼ë¥¼ ì‚´í´ë³´ë©´, ê° ì…€ì˜ ê¸°ëŒ€ë¹ˆë„ê°€ ëª¨ë‘ 5 ì´ìƒì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
    from scipy.stats import chi2_contingency
    result = chi2_contingency(phone_data)
    result[3]
    ^à¼ˆ array([[46.08, 49.92],
    ^à¼ˆ [20.16, 21.84],
    ^à¼ˆ [29.76, 32.24]])
    234 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    ê²€ì •í†µê³„ëŸ‰ê³¼ pâ€‘value
    x_squared, p_value, df, expected = result
    print('xà¼¡squared:',x_squared)
    ^à¼ˆ xà¼¡squared: 3.2199060739887355
    print('pà¼¡value:',p_value)
    ^à¼ˆ pà¼¡value: 0.19989700161872206
    ì¹´ì´ì œê³± í†µê³„ëŸ‰ 3.219ì— ëŒ€ì‘í•˜ëŠ” pâ€‘value 0.199ëŠ” ìœ ì˜ìˆ˜ì¤€ 5%ë³´ë‹¤ í¬ë¯€ë¡œ, ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜
    ì§€ ëª»í•œë‹¤. ë”°ë¼ì„œ, íœ´ëŒ€í° ì‚¬ìš©ì—¬ë¶€ëŠ” ì •ë‹¹ì§€ì§€ì™€ëŠ” ê´€ë ¨ì´ ì—†ë‹¤ (ë…ë¦½ì´ë‹¤) ë¼ê³  íŒë‹¨í•œë‹¤.
    ë¬¸ì œ 2. ì—¬ìì•„ì´ vs. ë‚¨ìì•„ì´
    ë‹¤ìŒì€ 4ìë…€ë¥¼ ë‘” 130ê°€êµ¬ë¥¼ ì¡°ì‚¬í•˜ì—¬ ì—¬ìì•„ì´ì˜ ìˆ˜ë¥¼ ì¡°ì‚¬í•œ ìë£Œì´ë‹¤. ì—¬ì ì•„ì´ì˜ ì¶œìƒ ë¹„ìœ¨ì´
    50% ì¸ì§€ ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ê²€ì •í•´ë³´ì„¸ìš”.
    í‘œ 11.6: 4ìë…€ ê°€ì • ì—¬ìì•„ì´ ìˆ«ì ì¡°ì‚¬ ê²°ê³¼
    Girl Frequency
    0 10
    1 31
    2 44
    3 34
    4 11
    ì´í•­ë¶„í¬
    í™•ë¥ ë³€ìˆ˜ ğ‘‹ê°€ ì´í•­ë¶„í¬ ğ‘›, ğ‘ë¥¼ ë”°ë¥¼ ë•Œ, ğ‘‹ì˜ í™•ë¥ ì§ˆëŸ‰í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
    ğ‘ (ğ‘¥; ğ‘›, ğ‘) = ( ğ‘›
    ğ‘¥
    ) ğ‘ğ‘¥
    (1 âˆ’ ğ‘)ğ‘›âˆ’ğ‘¥
    ê·€ë¬´ê°€ì„¤ vs. ëŒ€ë¦½ê°€ì„¤
    â€¢ ğ»0
    : ì—¬ìì•„ì´ì˜ ì¶œìƒìœ¨ì€ 0.5ì´ë‹¤.
    â€¢ ğ»ğ´: ì—¬ìì•„ì´ì˜ ì¶œìƒìœ¨ì€ 0.5ê°€ ì•„ë‹ˆë‹¤.
    ê¸°ëŒ€ë¹ˆë„
    ê·€ë¬´ê°€ì„¤ í•˜ì—ì„œ 4ìë…€ ê°€ì •ì—ì„œ ì—¬ìì•„ì´ì˜ ìˆ«ìëŠ” ì´í•­ë¶„í¬ ğ‘› = 4, ğ‘ = 0.5ì—ì„œ ê´€ì°°ëœ ê´€ì°°ê°’ì´
    ë¼ ìƒê°í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ 4ìë…€ ê°€êµ¬ì—ì„œ ì—¬ìì•„ì´ê°€ 0ëª…ì—ì„œ 4ëª…ì´ ìˆì„ í™•ë¥ ì„ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í• 
    ìˆ˜ ìˆë‹¤.
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 235
    from scipy.stats import binom
    binom.pmf(range(5), 4, 0.5)
    ^à¼ˆ array([0.0625, 0.25 , 0.375 , 0.25 , 0.0625])
    ìœ„ì˜ í™•ë¥ ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ëŒ€ë¹ˆë„ë¥¼ êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
    130 * binom.pmf(range(5), 4, 0.5)
    ^à¼ˆ array([ 8.125, 32.5 , 48.75 , 32.5 , 8.125])
    ê¸°ëŒ€ ë¹ˆë„ê°€ ëª¨ë‘ 5ì´ìƒì´ë¯€ë¡œ ì¹´ì´ì œê³± ê²€ì •ì„ ì‹¤ì‹œí•  ìˆ˜ ìˆë‹¤.
    ì í•©ë„ê²€ì •
    chisq.test()ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê´€ì°°ê°’ê³¼ ëŒ€ì‘í•˜ëŠ” í™•ë¥ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ê²€ì •ì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.
    from scipy.stats import chisquare
    import numpy as np
    observed_frequencies = [10, 31, 44, 34, 11]
    expected_frequencies = binom.pmf(range(5), 4, 0.5) * sum(observed_frequencies)
    chisquare(observed_frequencies, expected_frequencies)
    ^à¼ˆ Power_divergenceResult(statistic=2.0512820512820507, pvalue=0.726327096627745)
    ê²€ì •í†µê³„ëŸ‰ 2.0513ì— ëŒ€ì‘í•˜ëŠ” ìœ ì˜í™•ë¥ ì¸ pâ€‘value ê°’ 0.7263ì´ ìœ ì˜ìˆ˜ì¤€ 5%ë³´ë‹¤ í¬ë¯€ë¡œ, ê·€ë¬´
    ê°€ì„¤ì„ ê¸°ê°í•˜ì§€ ëª»í•œë‹¤. ë”°ë¼ì„œ ì—¬ìì•„ì´ ì¶œìƒë¹„ìœ¨ì´ 50%ë¼ê³  íŒë‹¨í•œë‹¤.
    ë¬¸ì œ 3. ì§€ì—­ë³„ ëŒ€ì„  í›„ë³´ì˜ ì§€ì§€ìœ¨
    ì–´ëŠ ë„ì‹œì— ìˆëŠ” 3ê°œì˜ ì„ ê±°êµ¬ì—ì„œ íŠ¹ì •í›„ë³´ Aë¥¼ ì§€ì§€í•˜ëŠ” ìœ ê¶Œìì˜ ë¹„ìœ¨ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ê° ì„ ê±°
    êµ¬ì—ì„œ 300ëª…ì„ ë¬´ì‘ìœ„ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¡°ì‚¬í•œ ë°ì´í„°ì´ë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ í›„ë³´Aë¥¼ ì§€ì§€í•˜ëŠ”
    ë¹„ìœ¨ì´ 3ê°œ ì„ ê±°êµ¬ ê°„ì— ì°¨ì´ê°€ ìˆëŠ”ì§€ë¥¼ 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ê²€ì •í•˜ë¼.
    í‘œ 11.7: ì§€ì—­ë³„ ëŒ€ì„  í›„ë³´ì˜ ì§€ì§€ìœ¨
    êµ¬ë¶„ ì„ ê±°êµ¬ 1 ì„ ê±°êµ¬ 2 ì„ ê±°êµ¬ 3
    ì§€ì§€í•¨ 176 193 159
    ì§€ì§€í•˜ì§€ ì•ŠìŒ 124 107 141
    236 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    ê·€ë¬´ê°€ì„¤ vs. ëŒ€ë¦½ê°€ì„¤
    â€¢ ğ»0
    : ê° ì„ ê±°êµ¬ ë³„ A í›„ë³´ì˜ ì§€ì§€ìœ¨ì€ ë™ì¼í•˜ë‹¤. ğ‘1 = ğ‘2 = ğ‘3
    â€¢ ğ»ğ´: ì§€ì§€ìœ¨ì´ ë‹¤ë¥¸ ì„ ê±°êµ¬ê°€ ì ì–´ë„ í•˜ë‚˜ ì¡´ì¬í•œë‹¤.
    pâ€‘value ê³„ì‚° ë° ê²°ë¡  ë„ì¶œ
    import numpy as np
    from scipy.stats import chi2_contingency
    # ë°ì´í„° ì„¤ì •: êµì°¨í‘œ
    data = np.array([[176, 124], # ì„ ê±°êµ¬ 1
    [193, 107], # ì„ ê±°êµ¬ 2
    [159, 141]]) # ì„ ê±°êµ¬ 3
    chi2, p, df, expected = chi2_contingency(data)
    expected
    ^à¼ˆ array([[176., 124.],
    ^à¼ˆ [176., 124.],
    ^à¼ˆ [176., 124.]])
    ê° ì…€ì˜ ê¸°ëŒ€ë¹ˆë„ê°€ 5ë³´ë‹¤ í¬ë¯€ë¡œ ì¹´ì´ì œê³± ë™ì§ˆì„± ê²€ì •ì˜ ê²°ê³¼ë¥¼ ì‹ ë¢° í•  ìˆ˜ ìˆë‹¤.
    print(chi2.round(3), p.round(3))
    ^à¼ˆ 7.945 0.019
    ê²€ì •í†µê³„ëŸ‰ 7.9454ì— ëŒ€ì‘í•˜ëŠ” pâ€‘value ê°’ 0.019ê°€ ìœ ì˜ìˆ˜ì¤€ 0.05ë³´ë‹¤ ì‘ìœ¼ë¯€ë¡œ, ê·€ë¬´ê°€ì„¤ì„ ê¸°
    ê°í•œë‹¤. ë”°ë¼ì„œ ëª¨ë“  ì„ ê±°êµ¬ì˜ ì§€ì§€ìœ¨ì´ ê°™ì§€ ì•Šë‹¤ê³  íŒë‹¨í•  í†µê³„ì  ê·¼ê±°ê°€ ì¶©ë¶„í•˜ë‹¤.
    ë¬¸ì œ 4. ë°ì´í„°ê°€ íŠ¹ì •ë¶„í¬ë¥¼ ë”°ë¥¼ê¹Œ?
    ë‹¤ìŒì˜ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ë•Œ, ì¹´ì´ì œê³± ê²€ì •ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ê°€ ëª¨ìˆ˜ê°€ 2ì¸ ì§€ìˆ˜ë¶„í¬ë¥¼ ë”°ë¥´ëŠ”ì§€
    ìœ ì˜ìˆ˜ì¤€ 5% í•˜ì—ì„œ ê²€ì •í•´ë³´ì„¸ìš”.
    0.211, 0.098, 0.736, 0.091, 0.756, 1.039, 0.391, 0.172, 2.113, 0.013, 0.073, 0.812, 0.132,
    0.263, 0.124, 0.339, 0.092, 0.24, 0.438, 0.584, 0.722, 0.231, 0.033, 0.203, 0.177, 0.095, 0.352,
    0.023
    â€¢ ë°ì´í„°ëŠ” 3ê°œ êµ¬ê°„ (0, 0.2], (0.2, 0.4], (0.4, Inf )ì„ ì‚¬ìš©í•´ì„œ ê²€ì •í•˜ì„¸ìš”.
    ë°ì´í„° êµ¬ê°„ ë‚˜ëˆ„ê¸°
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 237
    x = [0.211, 0.098, 0.736, 0.091, 0.756, 1.039, 0.391, 0.172,
    2.113, 0.013, 0.073, 0.812, 0.132, 0.263, 0.124, 0.339,
    0.092, 0.24, 0.438, 0.584, 0.722, 0.231, 0.033, 0.203,
    0.177, 0.095, 0.352, 0.023]
    result = pd.cut(x,
    bins=[0, 0.2, 0.4, float("inf")],
    labels=["0,0.2", "0.2,0.4", "0.4,Inf"])
    print(result.value_counts())
    ^à¼ˆ 0,0.2 12
    ^à¼ˆ 0.2,0.4 8
    ^à¼ˆ 0.4,Inf 8
    ^à¼ˆ dtype: int64
    ê¸°ëŒ€ë¹ˆë„ êµ¬í•˜ê¸°
    ì£¼ì–´ì§„ êµ¬ê°„ì— ëŒ€ì‘í•˜ëŠ” í™•ë¥ ì„ êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
    from scipy.stats import expon
    import numpy as np
    x = [0.2, 0.4, float("inf")]
    rate = 2
    exp_cdf = expon.cdf(x, scale=1/rate)
    exp_p = exp_cdf - np.insert(exp_cdf, 0, 0)[:-1]
    print(exp_p)
    ^à¼ˆ [0.32967995 0.22099108 0.44932896]
    ì£¼ì–´ì§„ í™•ë¥ ë¡œ ê¸°ëŒ€ë¹ˆë„ë¥¼ êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
    exp_p * 28
    ^à¼ˆ array([ 9.23103871, 6.18775029, 12.581211 ])
    ê° ì…€ì˜ ê¸°ëŒ€ë¹ˆë„ ê°’ì´ 5ë³´ë‹¤ í¬ë¯€ë¡œ, ì¹´ì´ì œê³± ì í•©ë„ ê²€ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.
    ì í•©ë„ ê²€ì •
    238 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    from scipy.stats import chisquare
    chi2, p_value = chisquare(f_obs=result.value_counts(), f_exp=exp_p * 28)
    print("Chià¼¡square statistic:", chi2)
    ^à¼ˆ Chià¼¡square statistic: 3.0295112382237264
    print("pà¼¡value:", p_value)
    ^à¼ˆ pà¼¡value: 0.2198619083314235
    ê²€ì •í†µê³„ëŸ‰ ê°’ 3.0295ì— ëŒ€ì‘í•˜ëŠ” ìœ ì˜í™•ë¥  0.2199ëŠ” ìœ ì˜ìˆ˜ì¤€ 5%ë³´ë‹¤ í¬ë¯€ë¡œ, ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í• 
    ìˆ˜ ì—†ë‹¤.
    ì„¤ë¬¸ì¡°ì‚¬ í™˜ì ìˆ˜
    ìŠ¬í†µ ë³‘ì›ì—ì„œëŠ” ìµœê·¼ ë„ì…í•œ ì§„ë£Œ ì„œë¹„ìŠ¤ì— ëŒ€í•œ í™˜ì ë§Œì¡±ë„ë¥¼ í‰ê°€í•˜ê³ ì í•©ë‹ˆë‹¤. ë³‘ì›ì€ í™˜ìë“¤ì—
    ê²Œ ë§Œì¡±ë„ ì„¤ë¬¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ë¶„ë°°í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì„¤ë¬¸ì„ ì‹œì‘í•˜ê¸° ì „ì—, ë³‘ì›ì€ ì ì ˆí•œ í‘œë³¸ í¬ê¸°ë¥¼
    ê²°ì •í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
    ì„¤ë¬¸ì§€ëŠ” í™˜ìì˜ ì§„ë£Œ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ë§Œì¡±ë„ë¥¼ 7ì  ì²™ë„ë¡œ ë¬»ìŠµë‹ˆë‹¤. ë³‘ì›ì€ íŠ¹íˆ í™˜ì ì¤‘ ë§Œì¡±í•˜ê±°
    ë‚˜ ë§¤ìš° ë§Œì¡±í•˜ëŠ” ë¹„ìœ¨ ğ‘ì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤ (ì´ëŠ” 7ì  ì²™ë„ ì¤‘ ìƒìœ„ ë‘ ë‹¨ê³„ì— í•´ë‹¹í•©ë‹ˆë‹¤).
    ë³‘ì›ì€ ë§Œì¡±ë„ ì¶”ì •ì˜ ì‹ ë¢° ìˆ˜ì¤€ì„ 95%ë¡œ ì„¤ì •í•˜ë ¤ê³  í•˜ë©°, ì˜¤ì°¨ ë²”ìœ„ëŠ” 3% ë˜ëŠ” 0.03 ì´í•˜ë¡œ ì›
    í•©ë‹ˆë‹¤. ë³´ìˆ˜ì ì¸ ì¶”ì •ì„ ìœ„í•˜ì—¬ í™•ë¥ ì€ 0.5ë¡œ ê°€ì •í•˜ê³ ì í•©ë‹ˆë‹¤. ì¡°ê±´ ë§Œì¡±ì„ ìœ„í•˜ì—¬ ì„¤ë¬¸ì— í•„ìš”í•œ
    ìµœì†Œ í™˜ì ìˆ˜ë¥¼ êµ¬í•´ì£¼ì„¸ìš”.
    ê³µì‹ì„ ì‚¬ìš©í•œ í‘œë³¸ìˆ˜ êµ¬í•˜ê¸°
    ì‹ ë¢°êµ¬ê°„ ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ í‘œë³¸ìˆ˜ì™€ ê´€ë ¨í•œ ë‹¤ìŒê³¼ ê°™ì€ ê³µì‹ì„ ìœ ë„í•  ìˆ˜ ìˆë‹¤.
    Ì‚ğ‘(1 âˆ’ Ì‚ğ‘)
    (
    0.03
    ğ‘§ğ›¼/2 )
    2 â‰¤ ğ‘›
    ì—¬ê¸°ì— Ì‚ğ‘ ê°’ì„ 0.5ë¡œ ê°€ì •í•˜ê³  ğ‘› êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
    from scipy.stats import norm
    p_hat = 0.5
    p_hat * (1-p_hat) / (0.03 / norm.ppf(0.975))^*2
    ^à¼ˆ 1067.0718946372572
    ë”°ë¼ì„œ í•„ìš”í•œ í‘œë³¸ ìˆ˜ëŠ” 1068ê°œ ì´ë‹¤.
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 239
    ì„¤ë¬¸ì¡°ì‚¬ í™˜ì ìˆ˜ 2
    ë‹¤ìŒì€ ìŠ¬í†µ ë³‘ì›ì—ì„œ ì‘ë…„ì— ì¡°ì‚¬í•´ë†“ì€ í™˜ìë“¤ì˜ ë§Œì¡±ë„ ì¡°ì‚¬ ê²°ê³¼ ì…ë‹ˆë‹¤.
    7, 7, 6, 7, 6, 3, 6, 4, 5, 2, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6
    ìœ„ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ë¬¸ì— í•„ìš”í•œ ìµœì†Œ í™˜ì ìˆ˜ë¥¼ êµ¬í•´ì£¼ì„¸ìš”. ë³‘ì›ì€ ë§Œì¡±ë„ ì¶”ì •ì˜ ì‹ ë¢°
    ìˆ˜ì¤€ì„ 98%ë¡œ ì„¤ì •í•˜ë ¤ê³  í•˜ë©°, ì˜¤ì°¨ ë²”ìœ„ëŠ” 2% ë˜ëŠ” 0.02 ì´í•˜ë¡œ ì›í•©ë‹ˆë‹¤.
    í‘œë³¸ ìˆ˜ êµ¬í•˜ê¸° (ë°ì´í„° ì‚¬ìš©)
    í‘œë³¸ì„ êµ¬í•˜ëŠ” ê²ƒì€ ìœ„ì—ì„œ ì‚¬ìš©í•œ ê³µì‹ì„ ê·¸ëŒ€ë¡œ ì´ìš©í•  ìˆ˜ ìˆë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ì—ì„œ 6ì ê³¼ 7ì ì˜
    ë¹„ìœ¨ì„ êµ¬í•˜ì.
    import numpy as np
    # Convert data to numpy array
    data_np = np.array([7, 7, 6, 7, 6, 3, 6, 4, 5, 2,
    7, 6, 6, 6, 6, 6, 6, 6, 7, 6])
    # Calculate the proportion using numpy
    p_hat_np = np.mean((data_np ^à¼° 6) | (data_np ^à¼° 7))
    p_hat_np
    ^à¼ˆ 0.8
    ë§Œì¡±ë„ ì¶”ì •ê°’ì€ 0.8ë¡œ ì„¤ì •í•œë‹¤.
    from scipy.stats import norm
    p_hat = 0.8
    p_hat * (1-p_hat) / (0.02 / norm.ppf(0.99))^*2
    ^à¼ˆ 2164.757772421736
    ë”°ë¼ì„œ ì£¼ì–´ì§„ ì¡°ê±´ì„ ë§Œì¡±í•˜ê¸° ìœ„í•œ í•„ìš”í•œ ì´ í‘œë³¸ìˆ˜ëŠ” 2165ëª…ì´ë‹¤.
    ìœ ê¶Œìì˜ ë§ˆìŒ
    ìŠ¬í†µ ì‹ ë¬¸ì‚¬ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ 42ëª…ì˜ ì‹œë¯¼ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì§€ë‚œ 1ì›” A ëŒ€í†µë ¹ í›„ë³´ë¥¼ ì§€ì§€í•˜ëŠ” ì¡°ì‚¬
    í•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ëŒ€í†µë ¹ì´ ëœ A í›„ë³´ì˜ ì„ê¸° ì‹œì‘ í›„ 6ê°œì›”ì´ ì§€ë‚œ ì˜¤ëŠ˜, ë‹¤ì‹œ í•œë²ˆ ë™ì¼ ì¸ì›ë“¤ì—ê²Œ
    ì „í™”ë¥¼ ê±¸ì–´ ëŒ€í†µë ¹ í›„ë³´ë¥¼ ì§€ì§€í•˜ëŠ”ì§€ ë¬¼ì–´ë³¸ ê²°ê³¼ì…ë‹ˆë‹¤.
    ë‹¹ì„  í›„ ì§€ì§€ì—¬ë¶€
    ë‹¹ì„  ì „ ì§€ì§€ì—¬ë¶€ ì§€ì§€í•¨ ì§€ì§€í•˜ì§€ ì•ŠìŒ
    ì§€ì§€í•¨ 17 7
    240 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    ë‹¹ì„  í›„ ì§€ì§€ì—¬ë¶€
    ì§€ì§€í•˜ì§€ ì•ŠìŒ 5 13
    ì‚¬ëŒë“¤ì˜ A í›„ë³´ì— ëŒ€í•œ ì§€ì§€ìœ¨ì´ ë‹¹ì„  ì „ê³¼ ë‹¹ì„  í›„ ë³€í•˜ì˜€ëŠ”ì§€ ê²€ì •í•´ë³´ì„¸ìš”.
    McNemar ê²€ì •
    McNemar ê²€ì •ì€ 2x2 êµì°¨í‘œ(contingency table)ì— ëŒ€í•œ ì¹´ì´ì œê³± ê²€ì •ì˜ íŠ¹ë³„í•œ ê²½ìš°ì…ë‹ˆë‹¤.
    ì£¼ë¡œ, ë‘ ì‹œì  ë˜ëŠ” ë‘ ì¡°ê±´ì—ì„œ ë™ì¼í•œ ëŒ€ìƒë“¤ì˜ ë²”ì£¼í˜• ì‘ë‹µì„ ë¹„êµí•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ì „ì²˜ë¦¬ ê²°ê³¼ A ì „ì²˜ë¦¬ ê²°ê³¼ B
    ì²˜ë¦¬ ì „ A a b
    ì²˜ë¦¬ ì „ B c d
    â€¢ ê²€ì • í†µê³„ëŸ‰: ğœ’
    2 =
    (ğ‘âˆ’ğ‘)2
    ğ‘+ğ‘ âˆ¼ ğœ’2
    (1)
    ë¨¼ì €, McNemar ê²€ì •ì˜ ê·€ë¬´ ê°€ì„¤ê³¼ ëŒ€ë¦½ ê°€ì„¤ì„ ì„¤ì •í•©ë‹ˆë‹¤:
    ê·€ë¬´ ê°€ì„¤ : ë‹¹ì„  ì „ê³¼ ë‹¹ì„  í›„ì˜ ì§€ì§€ìœ¨ì€ ë™ì¼í•˜ë‹¤. ëŒ€ë¦½ ê°€ì„¤ : ë‹¹ì„  ì „ê³¼ ë‹¹ì„  í›„ì˜ ì§€ì§€ìœ¨ì€
    ë‹¤ë¥´ë‹¤.
    from scipy.stats import chi2
    b = 7
    c = 5
    # ê²€ì •í†µê³„ëŸ‰ ê³„ì‚°
    stat = (b - c)^*2 / (b + c)
    stat
    # ìœ ì˜í™•ë¥ 
    ^à¼ˆ 0.3333333333333333
    1 - chi2.cdf(stat, 1)
    ^à¼ˆ 0.5637028616507731
    ê²€ì •í†µê³„ëŸ‰ ê°’ 0.3ì— ëŒ€ì‘í•˜ëŠ” pâ€‘value ê°’ì´ ìœ ì˜ ìˆ˜ì¤€ 0.05ë³´ë‹¤ í¬ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì§€ ëª»
    í•œë‹¤. ë”°ë¼ì„œ ë‹¹ì„  ì „ê³¼ í›„ì˜ ì§€ì§€ìœ¨ì€ ë™ì¼í•˜ë‹¤ê³  íŒë‹¨í•œë‹¤.
    statsmodels ë²„ì „ (ì°¸ê³ )
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 241
    from statsmodels.stats.contingency_tables import mcnemar
    # ì£¼ì–´ì§„ ë°ì´í„°
    observed = [[17, 7], [5, 13]]
    # McNemar ê²€ì • ìˆ˜í–‰ (ì˜µì…˜ 2ê°œ ê¼­ êº¼ì¤˜ì•¼ í•¨)
    result = mcnemar(observed, exact=False, correction=False)
    print("ê²€ì • í†µê³„ëŸ‰:", result.statistic)
    ^à¼ˆ ê²€ì • í†µê³„ëŸ‰: 0.3333333333333333
    print("p-ê°’:", result.pvalue)
    ^à¼ˆ p-ê°’: 0.5637028616507731
    Chapter 6. ë¶„ì‚°ë¶„ì„ ì¹œí•´ì§€ê¸°
    í­ê·„ì˜ ë¶€ë¦¬ê¸¸ì´
    palmerpenguins íŒ¨í‚¤ì§€ì˜ penguins ë°ì´í„°ì—ëŠ” í­ê·„ ì¢…ë¥˜ë³„ ë¶€ë¦¬ê¸¸ì´ ( bill_length_mm ) ì •ë³´ê°€ ë“¤
    ì–´ìˆë‹¤. í­ê·„ì˜ ì¢…ë¥˜ì— ë”°ë¼ì„œ ë¶€ë¦¬ê¸¸ì´ê°€ ë‹¤ë¥´ë‹¤ê³  í•  ìˆ˜ ìˆëŠ”ì§€ ìœ ì˜ìˆ˜ì¤€ 1% í•˜ì—ì„œ ê²€ì •í•´ë³´ì„¸ìš”.
    from palmerpenguins import load_penguins
    penguins = load_penguins()
    penguins.isnull().sum()
    ^à¼ˆ species 0
    ^à¼ˆ island 0
    ^à¼ˆ bill_length_mm 2
    ^à¼ˆ bill_depth_mm 2
    ^à¼ˆ flipper_length_mm 2
    ^à¼ˆ body_mass_g 2
    ^à¼ˆ sex 11
    ^à¼ˆ year 0
    ^à¼ˆ dtype: int64
    ë³€ìˆ˜ ë³„ ê²°ì¸¡ì¹˜ ì •ë³´ë¥¼ ì¡°ì‚¬í•´ ë³´ì•˜ì„ ë•Œ, ë…ë¦½ ë³€ìˆ˜ì¸ ë¶€ë¦¬ê¸¸ì´ê°€ ê²°ì¸¡ì¸ ë°ì´í„° 2ê°œê°€ ì¡´ì¬í•œë‹¤.
    ì´ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ì„ ì§„í–‰í•˜ë„ë¡ í•˜ì.
    242 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    my_penguins = penguins[['species', 'bill_length_mm']].dropna()
    print(my_penguins.shape)
    ^à¼ˆ (342, 2)
    ì´ 342ê°œì˜ ê´€ì°°ê°’ì´ ì¡´ì¬í•œë‹¤. í­ê·„ ì¢… ë³„ ë¶€ë¦¬ ê¸¸ì´ì˜ ëª¨í‰ê· ì´ ë‹¤ë¥¸ì§€ ê²€ì •í•˜ê¸° ìœ„í•˜ì—¬ ANOVA
    ë¥¼ ì§„í–‰í•˜ë„ë¡ í•œë‹¤.
    ê·€ë¬´ vs. ëŒ€ë¦½ê°€ì„¤
    â€¢ ê·€ë¬´ê°€ì„¤: í­ê·„ ì¢…ë³„ ë¶€ë¦¬ê¸¸ì´ í‰ê· ì€ ë™ì¼í•˜ë‹¤.
    â€“ ğœ‡ğ‘ğ‘‘ğ‘’ğ‘™ğ‘–ğ‘’ = ğœ‡ğ‘â„ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘ğ‘ = ğœ‡ğ‘”ğ‘’ğ‘›ğ‘¡ğ‘œğ‘œ
    â€¢ ëŒ€ë¦½ê°€ì„¤: í­ê·„ ì¢… ê°„ ë¶€ë¦¬ ê¸¸ì´ê°€ ë‹¤ë¥¸ ê·¸ë£¹ì´ ì ì–´ë„ í•˜ë‚˜ ì¡´ì¬í•œë‹¤.
    â€“ Not all of the ğœ‡ğ‘–
    are equal
    Pythonì—ì„œ ANOVA í…Œì´ë¸” êµ¬í•˜ê¸°
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    model = ols('bill_length_mm ~ C(species)', data=my_penguins).fit()
    aov_table = sm.stats.anova_lm(model, typ=2)
    print(aov_table)
    ^à¼ˆ sum_sq df F PR(>F)
    ^à¼ˆ C(species) 7194.317439 2.0 410.600255 2.694614e-91
    ^à¼ˆ Residual 2969.888087 339.0 NaN NaN
    ANOVA í…Œì´ë¸” ê²°ê³¼ë¥¼ ë³´ë©´, ê·€ë¬´ê°€ì„¤ í•˜ì—ì„œ ê²€ì • í†µê³„ëŸ‰ì¸ F ê°’ì´ 410.6ì´ ë‚˜ì™”ê³ , ëŒ€ì‘í•˜ëŠ”
    pâ€‘valueëŠ” 2eâ€‘91ë³´ë‹¤ ì‘ì€ ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤. ë”°ë¼ì„œ ìœ ì˜ìˆ˜ì¤€ 1%ë³´ë‹¤ í›¨ì”¬ ì‘ìœ¼ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ì„
    ê¸°ê°í•œë‹¤. í­ê·„ ì¢… ê°„ ë¶€ë¦¬ê¸¸ì´ê°€ ë‹¤ë¥¸ ì¢…ì´ ì ì–´ë„ í•˜ë‚˜ ì¡´ì¬í•œë‹¤.
    ìœ„ì˜ ANOVA ê²€ì • ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ì§€ ANOVA ëª¨ë¸ì˜ ê°€ì •ì„ ì²´í¬í•˜ì.
    â€¢ ì”ì°¨ì˜ ì •ê·œì„±
    â€¢ ì”ì°¨ì˜ ë“±ë¶„ì‚°ì„±
    import matplotlib.pyplot as plt
    import scipy.stats as stats
    fig = plt.figure(figsize= (10, 10))
    ax = fig.add_subplot(111)
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 243
    normality_plot, stat = stats.probplot(model.resid, plot= plt, rvalue= True)
    ax.set_title("Probability plot of model residual's", fontsize= 10)
    ^à¼ˆ Text(0.5, 1.0, "Probability plot of model residual's")
    ax.set;
    plt.show()
    3 2 1 0 1 2 3
    Theoretical quantiles
    5
    0
    5
    10
    Ordered Values
    R
    2 = 0.9878
    Probability plot of model residual's
    ê·¸ë˜í”„ë¡œ ë³´ì•„ ì”ì°¨ì˜ QQ plotì´ ê¸°ì¤€ì„ ì„ ë”°ë¼ ë¶„í¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì •ê·œì„±ì„
    ë§Œì¡±í•  ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤. ìµœì¢… íŒë‹¨ì„ ìœ„í•´ì„œ ìƒ¤í”¼ë¡œâ€‘ìœŒí¬ ê²€ì •ì„ ìˆ˜í–‰í•œë‹¤.
    â€¢ ê·€ë¬´ê°€ì„¤: ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤: ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠëŠ”ë‹¤.
    stats.shapiro(model.resid)
    ^à¼ˆ ShapiroResult(statistic=0.989031195640564, pvalue=0.011304551735520363)
    ìƒ¤í”¼ë¡œ ìœŒí¬ ê²€ì •ì˜ ê²€ì • í†µê³„ëŸ‰ ê°’ ğ‘Š = 0.98903ì— ëŒ€ì‘í•˜ëŠ” pâ€‘valueê°’ì´ 0.01131ë¡œ ì£¼ì–´ì§„
    ìœ ì˜ìˆ˜ì¤€ 0.01ë³´ë‹¤ í¬ë¯€ë¡œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•  ìˆ˜ ì—†ë‹¤. ë”°ë¼ì„œ ì”ì°¨ê°€ ì •ê·œì„±ì„ ë§Œì¡±í•œë‹¤ê³  íŒë‹¨í•œë‹¤.
    ë‹¤ìŒì€ ì”ì°¨ì˜ ë“±ë¶„ì‚° ê²€ì •ì„ ìœ„í•˜ì—¬ leveneâ€™s ê²€ì •ì„ ìˆ˜í–‰í•˜ë„ë¡ í•œë‹¤.
    â€¢ ê·€ë¬´ê°€ì„¤: í­ê·„ ì¢…ë³„ ì”ì°¨ì˜ ë¶„ì‚°ì€ ê°™ë‹¤.
    244 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    â€“ ğœ
    2
    ğ‘ğ‘‘ğ‘’ğ‘™ğ‘–ğ‘’ = ğœ2
    ğ‘â„ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘ğ‘ = ğœ2
    ğ‘”ğ‘’ğ‘›ğ‘¡ğ‘œğ‘œ
    â€¢ ëŒ€ë¦½ê°€ì„¤: í­ê·„ ì¢…ë³„ ì”ì°¨ì˜ ë¶„ì‚° ì¤‘ ë‹¤ë¥¸ ìŒì´ ì ì–´ë„ í•˜ë‚˜ ì¡´ì¬í•œë‹¤.
    â€“ Not all of the ğœ
    2
    ğ‘–
    s are equal
    stats.levene(my_penguins[my_penguins['species'] ^à¼° 'Adelie']['bill_length_mm'],
    my_penguins[my_penguins['species'] ^à¼° 'Chinstrap']['bill_length_mm'],
    my_penguins[my_penguins['species'] ^à¼° 'Gentoo']['bill_length_mm'],
    center='mean')
    ^à¼ˆ LeveneResult(statistic=2.833610648953925, pvalue=0.060193797718201124)
    ê²€ì •í†µê³„ëŸ‰ ê°’ 2.833ì— ëŒ€ì‘í•˜ëŠ” pâ€‘valueëŠ” 0.06019ë¡œ ìœ ì˜ìˆ˜ì¤€ 1% í•˜ì—ì„œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì§€
    ëª»í•œë‹¤. ë”°ë¼ì„œ, ì”ì°¨ì˜ ì§‘ë‹¨ê°„ ë“±ë¶„ì‚°ì„± ê°€ì • ì—­ì‹œë„ ë§Œì¡±í•œë‹¤ê³  íŒë‹¨í•œë‹¤.
    ì‚¬í›„ê²€ì •
    ANOVAì˜ ê·€ë¬´ê°€ì„¤ì´ ê¸°ê°ë˜ì—ˆìœ¼ë¯€ë¡œ, ì‚¬í›„ ë¶„ì„ì„ í†µí•˜ì—¬ ëª¨í‰ê· ì´ ë‹¤ë¥¸ ê·¸ë£¹ì„ íŒë³€í•˜ê¸° ìœ„í•œ
    ì‚¬í›„ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤. ì‚¬í›„ ë¶„ì„ì€ aov() í•¨ìˆ˜ì˜ ê²°ê³¼ê°’ì„ ì…ë ¥ê°’ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆëŠ” TukeyHSD()ì„
    ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰í•˜ë„ë¡ í•œë‹¤.
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    tukey_result = pairwise_tukeyhsd(my_penguins['bill_length_mm'], my_penguins['species'], alpha=0.01)
    print(tukey_result)
    ^à¼ˆ Multiple Comparison of Means - Tukey HSD, FWER=0.01
    ^à¼ˆ ==========================================================
    ^à¼ˆ group1 group2 meandiff pà¼¡adj lower upper reject
    ^à¼ˆ ----------------------------------------------------------
    ^à¼ˆ Adelie Chinstrap 10.0424 -0.0 8.7745 11.3104 True
    ^à¼ˆ Adelie Gentoo 8.7135 -0.0 7.659 9.768 True
    ^à¼ˆ Chinstrap Gentoo -1.3289 0.0089 -2.6409 -0.017 True
    ^à¼ˆ ----------------------------------------------------------
    ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ë©´, ëª¨ë“  í­ê·„ ì¢…ë³„ ë¶€ë¦¬ ê¸¸ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤ê³  íŒë‹¨í•  ìˆ˜
    ìˆë‹¤. (ê° ì‚¬í›„ ê²€ì •ì˜ adjusted pâ€‘value ê°’ì´ 0.01ë³´ë‹¤ ì‘ë‹¤.)
    import seaborn as sns
    import matplotlib.pyplot as plt
    sns.set_palette(["#00AFBB", "#E7B800", "#FC4E07"])
    plt.figure(figsize=(8, 6))
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 245
    ^à¼ˆ <Figure size 800x600 with 0 Axes>
    sns.boxplot(x='species', y='bill_length_mm', data=my_penguins)
    ^à¼ˆ <AxesSubplot:xlabel='species', ylabel='bill_length_mm'>
    sns.swarmplot(x='species', y='bill_length_mm', data=my_penguins, color='black', size=2)
    ^à¼ˆ <AxesSubplot:xlabel='species', ylabel='bill_length_mm'>
    sns.pointplot(x='species', y='bill_length_mm', data=my_penguins, color='red', markers='o', errorbar=None)
    ^à¼ˆ <AxesSubplot:xlabel='species', ylabel='bill_length_mm'>
    plt.xlabel('Species')
    ^à¼ˆ Text(0.5, 26.722222222222207, 'Species')
    plt.ylabel('Bill length (mm)')
    ^à¼ˆ Text(52.847222222222214, 0.5, 'Bill length (mm)')
    plt.show()
    Adelie Gentoo Chinstrap
    Species
    35
    40
    45
    50
    55
    60
    Bill length (mm)
    ë”°ë¼ì„œ, ìœ ì˜ìˆ˜ì¤€ 0.01ì„ ê¸°ì¤€ìœ¼ë¡œ ê° í­ê·„ ì¢…ë³„ ë¶€ë¦¬ ê¸¸ì´ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤ê³ 
    íŒë‹¨í•˜ë©°, Adelie < Gentoo < Chinstrapì˜ ìˆœì„œëŒ€ë¡œ í‰ê· ì´ ì¦ê°€í•œë‹¤ê³  íŒë‹¨í•œë‹¤.
    246 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    ë“œë¦´ ë„êµ¬ ê²€ì • ì ˆì°¨ (Drilling process)
    drillingà¼¡toolà¼¡exam.csv ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë¬¼ìŒì— ë‹µí•˜ì„¸ìš”.
    ìŠ¬í†µ ì² ê³µ íšŒì‚¬ì—ì„œëŠ” 5ê°œì˜ ë¸Œëœë“œì˜ ë“œë¦´ ì†Œì¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì² íŒì— êµ¬ë©ì„ ëš«ì€ ì‘ì—…ì„ í•˜ê³  ìˆë‹¤.
    íšŒì‚¬ ì œí’ˆì€ 2.5cm ì§ê²½ì„ ê°€ì§„ ì² íŒì¸ë°, ë¸Œëœë“œ ë³„ ì‚¬ìš©í•˜ëŠ” ì†Œì¬ë“¤ì´ ë¯¸ì„¸í•˜ê²Œ ë‹¬ë¼, ì§ê²½ì— ì°¨ì´
    ê°€ ë°œìƒí•˜ëŠ”ì§€ ì•Œì•„ë³´ê³ ì í•œë‹¤. í’ˆì§ˆ íŒ€ì€ ì œí’ˆ í’ˆì§ˆì„ ìœ ì§€í•˜ê¸° ìœ„í•˜ì—¬ ì˜¨ë„ì˜ ì˜í–¥ë„ ì¡°ì‚¬í•˜ê¸°ë¡œ
    í•˜ì˜€ë‹¤. ìŠ¬í†µì´ëŠ” í•œ ëª…ì˜ í’ˆì§ˆ ê´€ë¦¬ì‚¬ì—ê²Œ ê°ê¸° ë‹¤ë¥¸ ì˜¨ë„ì—ì„œ ë¸Œëœë“œë³„ ë“œë¦´ì„ ë¬´ì‘ìœ„ë¡œ 20ê°œì”©
    ì„ íƒí•˜ì—¬ ëš«ì€ êµ¬ë©ì˜ ì§ê²½ì„ ì¸¡ì •í•˜ë„ë¡ í•˜ì˜€ë‹¤.
    1) ë°ì´í„°ë¥¼ ì‚¬ìš© ê° ë¸Œëœë³„, ì˜¨ë„ë³„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì •ë¦¬ í‘œë¥¼ ë§Œë“œì„¸ìš”.
    ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (Wide í˜•íƒœ ë°ì´í„° ì „ì²˜ë¦¬ ì—°ìŠµ)
    import pandas as pd
    # Load the dataset
    data = pd.read_csv("./data/drillingà¼¡toolà¼¡exam.csv", skiprows=1)
    data.head()
    ^à¼ˆ Brand Temp Mesurement 1 ^^. Mesurement 18 Mesurement 19 Mesurement 20
    ^à¼ˆ 0 A 100 25.031768 ^^. 25.029239 25.029938 25.032016
    ^à¼ˆ 1 A 200 25.027100 ^^. 25.028416 25.028347 25.028968
    ^à¼ˆ 2 A 300 25.024713 ^^. 25.023498 25.026318 25.025532
    ^à¼ˆ 3 B 100 25.018161 ^^. 25.017452 25.018334 25.016180
    ^à¼ˆ 4 B 200 25.020642 ^^. 25.020781 25.018409 25.021757
    ^à¼ˆ
    ^à¼ˆ [5 rows x 22 columns]
    ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ë©´ ë¸Œëœë“œë³„ ì˜¨ë„ë³„ë¡œ ì´ 20ê°œì˜ ì§ê²½ ë°ì´í„°ê°€ ì¡´ì¬í•œë‹¤. ê° ê·¸ë£¹ë³„ í‰ê· ê³¼ í‘œì¤€
    í¸ì°¨ê°’ì„ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
    drill_long = pd.melt(
    data, id_vars=['Brand', 'Temp'],
    value_vars=[col for col in data.columns if 'Mesurement' in col],
    var_name='Mesurement',
    value_name='mm')
    drill_long.head()
    ^à¼ˆ Brand Temp Mesurement mm
    ^à¼ˆ 0 A 100 Mesurement 1 25.031768
    ^à¼ˆ 1 A 200 Mesurement 1 25.027100
    ^à¼ˆ 2 A 300 Mesurement 1 25.024713
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 247
    ^à¼ˆ 3 B 100 Mesurement 1 25.018161
    ^à¼ˆ 4 B 200 Mesurement 1 25.020642
    â€¢ ë¸Œëœë“œë³„ ì˜¨ë„ë³„ í‰ê· , í‘œì¤€í¸ì°¨í‘œ
    drill_long['mm'] = pd.to_numeric(drill_long['mm'])
    # Calculate mean and standard deviation grouped by Tool and Temp
    drilling_summary = drill_long.groupby(['Brand', 'Temp'])
    drilling_summary.agg(mean_mm=('mm', 'mean'), sd_mm=('mm', 'std')).reset_index()
    ^à¼ˆ Brand Temp mean_mm sd_mm
    ^à¼ˆ 0 A 100 25.030796 0.001195
    ^à¼ˆ 1 A 200 25.028082 0.000762
    ^à¼ˆ 2 A 300 25.025773 0.001013
    ^à¼ˆ 3 B 100 25.016513 0.001040
    ^à¼ˆ 4 B 200 25.020340 0.000814
    ^à¼ˆ 5 B 300 25.015927 0.000888
    ^à¼ˆ 6 C 100 25.006082 0.001162
    ^à¼ˆ 7 C 200 25.012751 0.001289
    ^à¼ˆ 8 C 300 25.009271 0.000939
    ^à¼ˆ 9 D 100 25.011982 0.000761
    ^à¼ˆ 10 D 200 25.019303 0.000846
    ^à¼ˆ 11 D 300 25.014145 0.001145
    ^à¼ˆ 12 E 100 24.997342 0.001214
    ^à¼ˆ 13 E 200 25.005625 0.001305
    ^à¼ˆ 14 E 300 25.000520 0.001012
    2) ë¸Œëœë“œë³„ ì˜¨ë„ë³„ë¡œ ANOVA main effect & interaction plotì„ ê·¸ë ¤ë³´ì„¸ìš”.
    import matplotlib.pyplot as plt
    import seaborn as sns
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    from statsmodels.graphics.factorplots import interaction_plot
    fig = interaction_plot(
    drill_long['Temp'], drill_long['Brand'], drill_long['mm'],
    colors=['red', 'blue', 'green', 'purple', 'orange'],
    markers=['D', '^', 'o', 's', '*'], ms=10)
    plt.show()
    248 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    100 150 200 250 300
    Temp
    25.00
    25.01
    25.02
    25.03
    mean of mm
    Brand
    A
    B
    C
    D
    E
    3) Twoâ€‘way ANOVA ë¶„ì„ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”.
    Twoâ€‘way ANOVAì˜ ê²½ìš° 3ê°œì˜ ê·€ë¬´ê°€ì„¤ì´ ì¡´ì¬í•œë‹¤.
    â€¢ ê·€ë¬´ê°€ì„¤1: Brand ë³€ìˆ˜ì˜ main effectê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤1: Brand ë³€ìˆ˜ì˜ main effectê°€ ì¡´ì¬í•œë‹¤.
    â€¢ ê·€ë¬´ê°€ì„¤2: Temp ë³€ìˆ˜ì˜ main effectê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤2: Temp ë³€ìˆ˜ì˜ main effectê°€ ì¡´ì¬í•œë‹¤.
    â€¢ ê·€ë¬´ê°€ì„¤3: Brand ë³€ìˆ˜ì™€ Temp ë³€ìˆ˜ì˜ interactionì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤3: Brand ë³€ìˆ˜ì™€ Temp ë³€ìˆ˜ì˜ interactionì´ ì¡´ì¬í•œë‹¤.
    # Conduct twoà¼¡way ANOVA
    formula = 'mm ~ C(Brand) + C(Temp) + C(Brand):C(Temp)'
    model = ols(formula, data=drill_long).fit()
    anova_table = sm.stats.anova_lm(model, typ=2)
    anova_table
    ^à¼ˆ sum_sq df F PR(>F)
    ^à¼ˆ C(Brand) 0.024130 4.0 5561.567051 4.952237e-269
    ^à¼ˆ C(Temp) 0.001299 2.0 598.805667 8.790226e-103
    ^à¼ˆ C(Brand):C(Temp) 0.000893 8.0 102.903992 1.874030e-79
    ^à¼ˆ Residual 0.000309 285.0 NaN NaN
    ANOVA í…Œì´ë¸”ì„ ì‚´í´ë³´ë©´, ê° ë³€ìˆ˜ì˜ main effectì— ëŒ€í•œ ê²€ì • í†µê³„ëŸ‰ê°’ì¸ Fê°’ì´ 5561.6ê³¼ 598.8
    ì´ ê³„ì‚°ë˜ì—ˆê³ , ëŒ€ì‘í•˜ëŠ” pâ€‘valueê°’ì´ ëª¨ë‘ 2eâ€‘16ë³´ë‹¤ ë‚®ì•„ì„œ ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ê·€ë¬´ê°€ì„¤ 1ê³¼ 2ê°€
    ê¸°ê°ëœë‹¤. ë”°ë¼ì„œ, ë‘ ë³€ìˆ˜ì˜ main effectê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨í•œë‹¤.
    ë‘ ë³€ìˆ˜ì˜ êµí˜¸ì‘ìš©ì„ ê²€ì •í•˜ëŠ” F ê°’ì˜ ê²½ìš° ì—­ì‹œ 102.9ê°€ ë‚˜ì™”ìœ¼ë©°, ëŒ€ì‘í•˜ëŠ” ìœ ì˜ìˆ˜ì¤€ ì—­ì‹œ 2eâ€‘16
    ë³´ë‹¤ ë‚®ì•„ì„œ ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ê·€ë¬´ê°€ì„¤ì´ ê¸°ê°ëœë‹¤.
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 249
    ë”°ë¼ì„œ, ë¸Œëœë“œë³„, ì˜¨ë„ë³„ êµ¬ë© í‰ê·  ì§ê²½ì€ ë‹¤ë¥´ë‹¤ê³  íŒë‹¨í•˜ê³ , ë‘ ë³€ìˆ˜ì˜ êµí˜¸ì‘ìš©ì— ì˜í–¥ì„ ë°›ëŠ”
    ë‹¤ê³  íŒë‹¨í•œë‹¤. ì•ì—ì„œ ì‘ì„±í•œ ê·¸ë˜í”„ë¥¼ ì°¸ê³ í•˜ë©´, ë¸Œëœë“œ ë³„ êµ¬ë© ì§ê²½ì˜ ì°¨ì´ê°€ ì˜¨ë„ê°€ ë‚®ì€ ê²½ìš°ì—
    ì˜¨ë„ê°€ ì¤‘ê°„ì¸ ê²½ìš°ì— ë¹„í•˜ì—¬ ì¢€ ë” ë§ì´ ì°¨ì´ê°€ ë‚˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
    4) ê° ë©”ì¸ effectê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê²½ìš° ì‚¬í›„ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.
    ë¸Œëœë“œì™€ ì˜¨ë„ ë³€ìˆ˜ì— ëŒ€í•˜ì—¬ ê° ê·¸ë£¹ì˜ í‰ê·  êµ¬ë© ì§ê²½ì´ ë‹¤ë¥´ë‹¤ê³  ë‚˜ì™”ìœ¼ë¯€ë¡œ, ê° ë³€ìˆ˜ì— ëŒ€í•˜ì—¬
    ì‚¬í›„ ë¶„ì„ì„ ì§„í–‰í•œë‹¤. ë¨¼ì € Brand ë³€ìˆ˜ì— ëŒ€í•˜ì—¬ ì‚¬í›„ë¶„ì„ì„ ì§„í–‰í•˜ê¸° ìœ„í•´ TukeyHSD() í•¨ìˆ˜ë¥¼
    ì‚¬ìš©í•œë‹¤.
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    posthoc_brand = pairwise_tukeyhsd(drill_long['mm'], drill_long['Brand'])
    print(posthoc_brand.summary())
    ^à¼ˆ Multiple Comparison of Means - Tukey HSD, FWER=0.05
    ^à¼ˆ ====================================================
    ^à¼ˆ group1 group2 meandiff pà¼¡adj lower upper reject
    ^à¼ˆ ----------------------------------------------------
    ^à¼ˆ A B -0.0106 -0.0 -0.0121 -0.0092 True
    ^à¼ˆ A C -0.0188 -0.0 -0.0203 -0.0174 True
    ^à¼ˆ A D -0.0131 -0.0 -0.0145 -0.0116 True
    ^à¼ˆ A E -0.0271 -0.0 -0.0285 -0.0256 True
    ^à¼ˆ B C -0.0082 -0.0 -0.0097 -0.0068 True
    ^à¼ˆ B D -0.0024 0.0001 -0.0039 -0.001 True
    ^à¼ˆ B E -0.0164 -0.0 -0.0179 -0.015 True
    ^à¼ˆ C D 0.0058 -0.0 0.0043 0.0072 True
    ^à¼ˆ C E -0.0082 -0.0 -0.0097 -0.0067 True
    ^à¼ˆ D E -0.014 -0.0 -0.0154 -0.0125 True
    ^à¼ˆ ----------------------------------------------------
    ê²°ê³¼ë¥¼ ì‚´í´ë³´ë©´ ë¸Œëœë“œ ë³€ìˆ˜ì˜ ëª¨ë“  ë ˆë²¨ì— ëŒ€í•˜ì—¬ ì‚¬í›„ ë¶„ì„ì„ ì§„í–‰í•œ ê²½ê³¼, pâ€‘valueê°’ì´ ëª¨ë‘ ë‹¤
    ë‚®ê²Œ ë‚˜ì˜¤ê³ , ë”°ë¼ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤ê³  íŒë‹¨í•  ìˆ˜ ìˆë‹¤.
    posthoc_temp = pairwise_tukeyhsd(drill_long['mm'], drill_long['Temp'])
    print(posthoc_temp.summary())
    ^à¼ˆ Multiple Comparison of Means - Tukey HSD, FWER=0.05
    ^à¼ˆ ===================================================
    ^à¼ˆ group1 group2 meandiff pà¼¡adj lower upper reject
    ^à¼ˆ ---------------------------------------------------
    ^à¼ˆ 100 200 0.0047 0.0012 0.0016 0.0078 True
    ^à¼ˆ 100 300 0.0006 0.8956 -0.0025 0.0037 False
    ^à¼ˆ 200 300 -0.0041 0.0054 -0.0072 -0.001 True
    250 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    ^à¼ˆ ---------------------------------------------------
    ì˜¨ë„ ë³€ìˆ˜ ì—­ì‹œ Low, Medium, High ê·¸ë£¹ ê°„ í‰ê·  ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤ëŠ”
    ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ ê³„ì‚°ëœ diff ê°’ì— ë¹„ì¶”ì–´ë³´ë©´ Low < High < Medium ìˆœìœ¼ë¡œ í‰ê·  êµ¬ë©
    ì§ê²½ì´ ì»¤ì ¸ê°„ë‹¤ê³  íŒë‹¨ í•  ìˆ˜ ìˆë‹¤.
    ê°€ì •ì²´í¬
    Two way ANONAì˜ ê²°ê³¼ë¥¼ ì‹ ë¢°í•˜ê¸° ìœ„í•´ì„œëŠ” ANOVAì—ì„œ ê°€ì •í•˜ê³  ìˆëŠ” ì”ì°¨ì˜ ì •ê·œì„±ê³¼ ë“±ë¶„
    ì‚°ì„±ì— ëŒ€í•œ ê²€ì •ì´ í•„ìš”í•˜ë‹¤.
    import scipy.stats as stats
    import pingouin as pg
    # QQ plot
    ax = pg.qqplot(model.resid, dist='norm')
    plt.ylim(-3, 3);
    plt.xlim(-3, 3);
    plt.show()
    ì”ì°¨ì˜ ì •ê·œì„±
    2 0 2
    Theoretical quantiles
    3
    2
    1
    0
    1
    2
    3
    Ordered quantiles
    R
    2 = 0.997
    ì”ì°¨ ê·¸ë˜í”„ë¥¼ ì‚´í´ë³´ë©´ ì”ì°¨ë“¤ì´ 0ì„ ì¤‘ì‹¬ìœ¼ë¡œ í¼ì ¸ìˆê³ , QQ plot ì—­ì‹œ ì •ê·œì„±ì„ ë§Œì¡±í•˜ëŠ” ê²ƒìœ¼ë¡œ
    íŒë‹¨ëœë‹¤. ì •í™•í•œ ê²€ì •ì„ ìœ„í•˜ì—¬ ìƒ¤í”¼ë¡œ ìœŒí¬ ê²€ì •ì„ ì‚¬ìš©í•˜ì—¬ ì •ê·œì„± ì²´í¬ë¥¼ í•˜ë„ë¡ í•˜ì.
    â€¢ ê·€ë¬´ê°€ì„¤: ì”ì°¨ê°€ ì •ê·œì„±ì„ ë”°ë¥¸ë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤: ì”ì°¨ê°€ ì •ê·œì„±ì„ ë”°ë¥´ì§€ ì•ŠëŠ”ë‹¤.
    stats.shapiro(model.resid)
    ^à¼ˆ ShapiroResult(statistic=0.9961785078048706, pvalue=0.6853092312812805)
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 251
    ê²€ì • í†µê³„ëŸ‰ ê°’ 0.996ì— ëŒ€ì‘í•˜ëŠ” pâ€‘valueê°’ì´ 0.6852ì´ë¯€ë¡œ ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ê·€ë¬´ê°€ì„¤ì„
    ê¸°ê°í•˜ì§€ ëª»í•œë‹¤. ë”°ë¼ì„œ ì •ê·œì„±ì„ ë§Œì¡±í•œë‹¤ê³  íŒë‹¨í•œë‹¤.
    ì”ì°¨ì˜ ë“±ë¶„ì‚°ì„±
    â€¢ ê·€ë¬´ê°€ì„¤: ì”ì°¨ë“¤ì˜ ê·¸ë£¹ë³„ ëª¨ë¶„ì‚°ì´ ë™ì¼í•˜ë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤: ì”ì°¨ë“¤ì˜ ê·¸ë£¹ë³„ ëª¨ë¶„ì‚° ì¤‘ ë‹¤ë¥¸ ê²ƒì´ ì ì–´ë„ í•˜ë‚˜ ì¡´ì¬í•œë‹¤.
    # ì¸í„°ë ‰ì…˜ ê·¸ë£¹ ë§Œë“¤ê¸°
    drill_long['Brand_Temp'] = drill_long['Brand'] + "_" + drill_long['Temp'].astype(str)
    group_vec = drill_long['Brand_Temp']
    levene_test = stats.levene(
    *[model.resid[group_vec ^à¼° i] for i in group_vec.unique()], center='mean')
    levene_test
    ^à¼ˆ LeveneResult(statistic=1.3624630069062795, pvalue=0.17083426897357204)
    ê²€ì •í†µê³„ëŸ‰ ê°’ 1.3625ì— ëŒ€ì‘í•˜ëŠ” pâ€‘value ê°’ 0.1708ì´ ìœ ì˜ìˆ˜ì¤€ 5%ë³´ë‹¤ í¬ë¯€ë¡œ ê·€ë¬´ ê°€ì„¤ì„
    ê¸°ê°í•  ìˆ˜ ì—†ë‹¤. ë”°ë¼ì„œ, ë“±ë¶„ì‚° ê°€ì •ë„ ë§Œì¡±í•œë‹¤ê³  íŒë‹¨í•œë‹¤.
    ê²°ê³¼ì ìœ¼ë¡œ ì•ì—ì„œ ìˆ˜í–‰í•œ two way ANOVA ì˜ ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆë‹¤.
    Chapter 7. íšŒê·€ë¶„ì„ì˜ ì´í•´
    í­ê·„ ë¶€ë¦¬ê¸¸ì´ì™€ ê¹Šì´ì˜ ê´€ê³„
    palmerpenguins íŒ¨í‚¤ì§€ì—ëŠ” ë‚¨ê·¹ Palmer stationì—ì„œ ê´€ì¸¡í•œ í­ê·„ ì •ë³´ë“¤ì´ í¬í•¨ëœ ë°ì´í„°ì´ë‹¤.
    import pandas as pd
    import numpy as np
    from palmerpenguins import load_penguins
    penguins = load_penguins()
    print(penguins.head())
    ^à¼ˆ species island bill_length_mm ^^. body_mass_g sex year
    ^à¼ˆ 0 Adelie Torgersen 39.1 ^^. 3750.0 male 2007
    ^à¼ˆ 1 Adelie Torgersen 39.5 ^^. 3800.0 female 2007
    ^à¼ˆ 2 Adelie Torgersen 40.3 ^^. 3250.0 female 2007
    ^à¼ˆ 3 Adelie Torgersen NaN ^^. NaN NaN 2007
    ^à¼ˆ 4 Adelie Torgersen 36.7 ^^. 3450.0 female 2007
    ^à¼ˆ
    ^à¼ˆ [5 rows x 8 columns]
    252 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    1) train_index ë¥¼ ì‚¬ìš©í•˜ì—¬ í­ê·„ ë°ì´í„°ì—ì„œ ì¸ë±ìŠ¤ì— ëŒ€ì‘í•˜ëŠ” í‘œë³¸ë“¤ì„ ë½‘ì•„ì„œ train_dataë¥¼
    ë§Œë“œì„¸ìš”. (ë‹¨, ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ê²½ìš° ì œê±°)
    np.random.seed(2022)
    train_index=np.random.choice(penguins.shape[0],200)
    train_data = penguins.iloc[train_index]
    train_data = train_data.dropna()
    train_data.head()
    ^à¼ˆ species island bill_length_mm ^^. body_mass_g sex year
    ^à¼ˆ 220 Gentoo Biscoe 43.5 ^^. 4700.0 female 2008
    ^à¼ˆ 173 Gentoo Biscoe 45.1 ^^. 5000.0 female 2007
    ^à¼ˆ 112 Adelie Biscoe 39.7 ^^. 3200.0 female 2009
    ^à¼ˆ 177 Gentoo Biscoe 46.1 ^^. 5100.0 male 2007
    ^à¼ˆ 240 Gentoo Biscoe 47.5 ^^. 4875.0 female 2009
    ^à¼ˆ
    ^à¼ˆ [5 rows x 8 columns]
    2) train_dataì˜ í­ê·„ ë¶€ë¦¬ê¸¸ì´ (bill_length_mm)ë¥¼ ë¶€ë¦¬ ê¹Šì´ (bill_depth_mm)ë¥¼ ì‚¬ìš©í•˜ì—¬
    ì‚°ì ë„ë¥¼ ê·¸ë ¤ë³´ì„¸ìš”.
    import matplotlib.pyplot as plt
    import seaborn as sns
    # Scatter plot using seaborn
    plt.figure(figsize=(10,6))
    ^à¼ˆ <Figure size 1000x600 with 0 Axes>
    sns.scatterplot(data=train_data,
    x='bill_length_mm',
    y='bill_depth_mm',
    hue='species',
    palette='deep', edgecolor='w', s=50)
    ^à¼ˆ <AxesSubplot:xlabel='bill_length_mm', ylabel='bill_depth_mm'>
    plt.title('Bill Length vs Bill Depth by Species')
    ^à¼ˆ Text(0.5, 1.0, 'Bill Length vs Bill Depth by Species')
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 253
    plt.grid(True)
    plt.show()
    35 40 45 50 55
    bill_length_mm
    13
    14
    15
    16
    17
    18
    19
    20
    21
    bill_depth_mm
    Bill Length vs Bill Depth by Species
    species
    Gentoo
    Adelie
    Chinstrap
    3) í­ê·„ ë¶€ë¦¬ê¸¸ì´ (bill_length_mm)ë¥¼ ë¶€ë¦¬ ê¹Šì´ (bill_depth_mm)ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ êµ¬í•˜ê³ , ë‘
    ë³€ìˆ˜ ì‚¬ì´ì— ìœ ì˜ë¯¸í•œ ìƒê´€ì„±ì´ ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì •í•´ë³´ì„¸ìš”.
    â€¢ ê·€ë¬´ê°€ì„¤ ğ»0
    : ë‘ ë³€ìˆ˜ì˜ ìƒê´€ê³„ìˆ˜ ğœŒ = 0
    â€¢ ëŒ€ë¦½ê°€ì„¤ ğ»ğ´: ë‘ ë³€ìˆ˜ì˜ ìƒê´€ê³„ìˆ˜ ğœŒ â‰  0
    ë‘ ë³€ìˆ˜ì˜ ìƒê´€ê³„ìˆ˜ ê²€ì •ì€ pearsonr() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.
    from scipy.stats import pearsonr
    # Calculate the Pearson correlation coefficient
    # and the pà¼¡value for testing nonà¼¡correlation
    corr_coef, p_value = pearsonr(train_data['bill_length_mm'], train_data['bill_depth_mm'])
    print(corr_coef)
    ^à¼ˆ -0.24938519717051547
    print(p_value)
    ^à¼ˆ 0.00040929638362032476
    ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ìƒê´€ê³„ìˆ˜ ê°’ â€‘0.2493ì— í•´ë‹¹í•˜ëŠ” pâ€‘value ê°’ 0.000409296ì´ ìƒë‹¹íˆ ì‘ìœ¼ë¯€ë¡œ,
    ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•œë‹¤. ë”°ë¼ì„œ, ë‘ ë³€ìˆ˜ì˜ ìƒê´€ê³„ìˆ˜ê°€ 0ì´ ì•„ë‹ˆë¼ëŠ” í†µê³„ì  ê·¼ê±°ê°€ ì¶©ë¶„í•˜ë‹¤.
    ìœ„ì˜ ê²€ì • ê²°ê³¼ë¥¼ ì‹ ë¢° í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•˜ì—¬, ìƒê´€ê´€ê³„ ë¶„ì„ì—ì„œ ê°€ì •í•˜ê³  ìˆëŠ” ì •ê·œì„±ì„
    ì²´í¬í•´ë³´ë„ë¡ í•˜ì.
    import statsmodels.api as sm
    import matplotlib.pyplot as plt
    import pingouin as pg
    254 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    # Set up the subplots: 1 row, 2 columns
    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    # Q-Q plot for bill_depth_mm on the left
    pg.qqplot(train_data['bill_depth_mm'], dist='norm', confidence=0.95, ax=axs[0])
    ^à¼ˆ <AxesSubplot:xlabel='Theoretical quantiles', ylabel='Ordered quantiles'>
    axs[0].set_title("bill_depth_mm")
    ^à¼ˆ Text(0.5, 1.0, 'bill_depth_mm')
    axs[0].set_ylim(-3, 3);
    axs[0].set_xlim(-3, 3);
    # Q-Q plot for bill_length_mm on the right
    ^à¼ˆ (-3.0, 3.0)
    pg.qqplot(train_data['bill_length_mm'], dist='norm', confidence=0.95, ax=axs[1])
    ^à¼ˆ <AxesSubplot:xlabel='Theoretical quantiles', ylabel='Ordered quantiles'>
    axs[1].set_title("bill_length_mm")
    ^à¼ˆ Text(0.5, 1.0, 'bill_length_mm')
    axs[1].set_ylim(-3, 3);
    axs[1].set_xlim(-3, 3);
    # Display the plots
    ^à¼ˆ (-3.0, 3.0)
    plt.tight_layout()
    plt.show()
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 255
    3 2 1 0 1 2 3
    Theoretical quantiles
    3
    2
    1
    0
    1
    2
    3
    Ordered quantiles
    R
    2 = 0.966
    bill_depth_mm
    3 2 1 0 1 2 3
    Theoretical quantiles
    3
    2
    1
    0
    1
    2
    3
    Ordered quantiles
    R
    2 = 0.967
    bill_length_mm
    ê° ë³€ìˆ˜ì— í•´ë‹¹í•˜ëŠ” QQ plotì„ ê·¸ë ¤ ë³´ì•˜ì„ ë•Œ, ë¶€ë¦¬ ê¸¸ì´ (bill length) ë³€ìˆ˜ì™€ ë¶€ë¦¬ ê¹Šì´ (bill
    depth) ë³€ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ê·¸ë˜í”„ëŠ” ì •ê·œì„±ì„ ë„ì§€ ì•ŠëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. Shapiroâ€‘Wilk ê²€ì • ê²°ê³¼
    ì—­ì‹œ ë‘ ê·¸ë£¹ í‘œë³¸ì´ ì •ê·œì„± ê°€ì •ì„ ìœ„ë°˜í•œ ë‹¤ëŠ” ê²ƒì„ ë§í•´ì£¼ê³  ìˆë‹¤.
    Shapiroâ€‘Wilk ê²€ì •
    â€¢ ê·€ë¬´ê°€ì„¤ ğ»0
    : ë°ì´í„°ì˜ ë¶„í¬ê°€ ì •ê·œì„±ì„ ëˆë‹¤.
    â€¢ ëŒ€ë¦½ê°€ì„¤ ğ»ğ´: ë°ì´í„°ì˜ ë¶„í¬ê°€ ì •ê·œì„±ì„ ë„ì§€ ëª»í•œë‹¤.
    import scipy.stats as sp
    sp.shapiro(train_data['bill_depth_mm'])
    ^à¼ˆ ShapiroResult(statistic=0.9621433019638062, pvalue=3.906726124114357e-05)
    sp.shapiro(train_data['bill_length_mm'])
    ^à¼ˆ ShapiroResult(statistic=0.9634734988212585, pvalue=5.4907886806176975e-05)
    ì¦‰, ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ë‘ ë³€ìˆ˜ ëª¨ë‘ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ê²Œ ë˜ë¯€ë¡œ, ìœ„ì˜ ìƒê´€ê³„ìˆ˜ ê²€ì • ê²°ê³¼ëŠ”
    ì‹ ë¢°í•  ìˆ˜ ì—†ë‹¤.
    4) í­ê·„ ë¶€ë¦¬ê¸¸ì´ (bill_length_mm)ë¥¼ ë¶€ë¦¬ ê¹Šì´ (bill_depth_mm)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ëª…í•˜ëŠ” íšŒê·€
    ëª¨ë¸ì„ ì í•©ì‹œí‚¨ í›„ 2ë²ˆì˜ ì‚°ì ë„ì— íšŒê·€ ì§ì„ ì„ ë‚˜íƒ€ë‚´ ë³´ì„¸ìš”. (ëª¨ë¸ 1)
    from statsmodels.formula.api import ols
    model1 = ols("bill_length_mm ~ bill_depth_mm", data=train_data).fit()
    model1.params
    ^à¼ˆ Intercept 55.410976
    ^à¼ˆ bill_depth_mm -0.706191
    ^à¼ˆ dtype: float64
    256 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    sns.scatterplot(data=train_data,
    x='bill_depth_mm', y='bill_length_mm',
    palette='deep', edgecolor='w', s=50)
    # Use the slope and intercept to plot the regression line
    ^à¼ˆ <AxesSubplot:xlabel='bill_depth_mm', ylabel='bill_length_mm'>
    x_values = train_data['bill_depth_mm']
    y_values = 55.4110 - 0.7062 * x_values
    plt.plot(x_values, y_values, color='red', label='Regression Line')
    ^à¼ˆ [<matplotlib.lines.Line2D object at 0x000001ABA622F708>]
    plt.title('Scatter plot of Bill Length vs Bill Depth with Regression Line')
    ^à¼ˆ Text(0.5, 1.0, 'Scatter plot of Bill Length vs Bill Depth with Regression Line')
    plt.grid(True)
    plt.legend()
    ^à¼ˆ <matplotlib.legend.Legend object at 0x000001ABA77E6F88>
    plt.show()
    14 16 18 20
    bill_depth_mm
    35
    40
    45
    50
    55
    bill_length_mm
    Scatter plot of Bill Length vs Bill Depth with Regression Line
    Regression Line
    5) ì í•©ëœ íšŒê·€ ëª¨ë¸ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œì§€ íŒë‹¨í•´ë³´ì„¸ìš”.
    ë¶€ë¦¬ ê¹Šì´ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ë¦¬ ê¸¸ì´ ë³€ìˆ˜ë¥¼ ì„¤ëª…í•˜ëŠ” íšŒê·€ ëª¨ë¸ì„ ì„¤ì •í•œë‹¤.
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 257
    model1.summary()
    ^à¼ˆ <class 'statsmodels.iolib.summary.Summary'>
    ^à¼ˆ ""
    ^à¼ˆ OLS Regression Results
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Dep. Variable: bill_length_mm Rà¼¡squared: 0.062
    ^à¼ˆ Model: OLS Adj. Rà¼¡squared: 0.057
    ^à¼ˆ Method: Least Squares Fà¼¡statistic: 12.93
    ^à¼ˆ Date: í† , 28 10 2023 Prob (Fà¼¡statistic): 0.000409
    ^à¼ˆ Time: 14:03:42 Log-Likelihood: -602.49
    ^à¼ˆ No. Observations: 197 AIC: 1209.
    ^à¼ˆ Df Residuals: 195 BIC: 1216.
    ^à¼ˆ Df Model: 1
    ^à¼ˆ Covariance Type: nonrobust
    ^à¼ˆ =================================================================================
    ^à¼ˆ coef std err t P>|t| [0.025 0.975]
    ^à¼ˆ ---------------------------------------------------------------------------------
    ^à¼ˆ Intercept 55.4110 3.392 16.336 0.000 48.721 62.101
    ^à¼ˆ bill_depth_mm -0.7062 0.196 -3.596 0.000 -1.093 -0.319
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Omnibus: 4.987 Durbin-Watson: 1.786
    ^à¼ˆ Prob(Omnibus): 0.083 Jarque-Bera (JB): 3.609
    ^à¼ˆ Skew: 0.193 Prob(JB): 0.165
    ^à¼ˆ Kurtosis: 2.461 Cond. No. 159.
    ^à¼ˆ ==============================================================================
    ^à¼ˆ
    ^à¼ˆ Notes:
    ^à¼ˆ [1] Standard Errors assume that the covariance matrix of the errors is correctly â†©
    specified.
    ^à¼ˆ ""
    ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ F ê²€ì • í†µê³„ëŸ‰ ê°’ 12.93ì— ëŒ€ì‘í•˜ëŠ” pâ€‘valueê°’ 0.000409ì— ë¹„ì¶”ì–´ ë³´ì•˜ì„ ë•Œ,
    íšŒê·€ ëª¨ë¸ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê²ƒìœ¼ë¡œ íŒë‹¨í•œë‹¤.
    6) ğ‘…2 ê°’ì„ êµ¬í•œ í›„ ì˜ë¯¸ë¥¼ í•´ì„í•´ ë³´ì„¸ìš”.
    ìœ„ì˜ ê²°ê³¼ê°’ì—ì„œ R square ê°’ì€ 0.062ì´ë©°, ì´ëŠ” íšŒê·€ëª¨ë¸ì´ ë°ì´í„° ì „ì²´ ë³€ë™ì„±ì˜ 6.21%ë¥¼ ì„¤
    ëª…í•˜ê³  ìˆë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤. ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ R square ê°’ì„ ë¯¸ë£¨ì–´ ë³´ì•˜ì„ë•Œ, ì¶”ê°€ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬
    ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë†’ì´ëŠ” ê²ƒì„ ê³ ë ¤í•  ìˆ˜ ìˆë‹¤.
    7) ì í•©ëœ íšŒê·€ ëª¨ë¸ì˜ ê³„ìˆ˜ë¥¼ í•´ì„í•´ ë³´ì„¸ìš”.
    â€¢ ì ˆí¸ê³¼ ê¸°ìš¸ê¸°ê°€ ëª¨ë‘ ìœ ì˜í•˜ê²Œ ë‚˜ì˜¤ì§€ë§Œ, ê° ë³€ìˆ˜ì˜ ëœ»ì„ ê³ ë ¤í•˜ë©´, ì ˆí¸ì˜ í•´ì„ì€ ë¬´ì˜ë¯¸í•˜ë‹¤.
    (ë¶€ë¦¬ ê¹Šì´ 0ì¸ ê²½ìš°, ë¶€ë¦¬ ê¸¸ì´ 56 mm)
    258 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    â€¢ ê¸°ìš¸ê¸° â€‘0.7062 ê°’ì˜ ì˜ë¯¸ëŠ”, íŒ”ë¨¸ í­ê·€ì˜ ê²½ìš° ë¶€ë¦¬ ê¹Šì´ê°€ 1 mm ì¦ê°€í•  ë•Œ, ë¶€ë¦¬ ê¸¸ì´ëŠ”
    0.7062 mm ë§Œí° ê°ì†Œí•˜ëŠ” ê²½í–¥ì„ ë³´ì¸ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤.
    8) 1ë²ˆì—ì„œ ì í•©í•œ íšŒê·€ ëª¨ë¸ì— ìƒˆë¡œìš´ ë³€ìˆ˜ (ì¢… â€‘ species) ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì„±ë³„ ë³€ìˆ˜
    ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì  ìƒ‰ê¹”ì„ ë‹¤ë¥´ê²Œ ì‹œê°í™” í•œ í›„ ì í•©ëœ ëª¨ë¸ì˜ íšŒê·€ ì§ì„ ì„ ì‹œê°í™” í•´ë³´ì„¸ìš”.
    (ëª¨ë¸ 2)
    model2 = ols("bill_length_mm ~ bill_depth_mm + species", data=train_data).fit()
    model2.params
    # Set up the plot
    ^à¼ˆ Intercept 14.577564
    ^à¼ˆ species[T.Chinstrap] 9.886486
    ^à¼ˆ species[T.Gentoo] 12.912783
    ^à¼ˆ bill_depth_mm 1.320354
    ^à¼ˆ dtype: float64
    sns.scatterplot(data=train_data,
    x='bill_depth_mm', y='bill_length_mm',
    hue='species', palette='deep', edgecolor='w', s=50)
    # Generate regression lines for each species
    ^à¼ˆ <AxesSubplot:xlabel='bill_depth_mm', ylabel='bill_length_mm'>
    for species in train_data['species'].unique():
    # Filter data by species
    subset = train_data[train_data['species'] ^à¼° species]
    # Predict values using the regression model
    x_vals = subset['bill_depth_mm'].sort_values()
    y_vals = model2.predict(pd.DataFrame({'bill_depth_mm': x_vals, 'species': species}))
    # Plot regression line for this species
    sns.lineplot(x=x_vals, y=y_vals, label=f'Regression Line ({species})')
    ^à¼ˆ <AxesSubplot:xlabel='bill_depth_mm', ylabel='bill_length_mm'>
    ^à¼ˆ <AxesSubplot:xlabel='bill_depth_mm', ylabel='bill_length_mm'>
    ^à¼ˆ <AxesSubplot:xlabel='bill_depth_mm', ylabel='bill_length_mm'>
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 259
    plt.title('Scatter plot of Bill Depth vs Bill Length with Regression Lines by Species')
    ^à¼ˆ Text(0.5, 1.0, 'Scatter plot of Bill Depth vs Bill Length with Regression Lines â†©
    by Species')
    plt.grid(True)
    plt.legend()
    ^à¼ˆ <matplotlib.legend.Legend object at 0x000001AB97FCD488>
    plt.show()
    14 16 18 20
    bill_depth_mm
    35
    40
    45
    50
    55
    bill_length_mm
    Scatter plot of Bill Depth vs Bill Length with Regression Lines by Species
    Gentoo
    Adelie
    Chinstrap
    Regression Line (Gentoo)
    Regression Line (Adelie)
    Regression Line (Chinstrap)
    ê²°ê³¼ë¥¼ ì‚´í´ë³´ë©´, ì¢… (species) ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ë¯€ë¡œì¨ íšŒê·€ì§ì„ ì˜ ë°©í–¥ì´ ë°”ë€Œì—ˆë‹¤. ë˜í•œ, ì „ì²´ì ì¸
    ë°ì´í„°ì˜ ì¶”ì„¸ë¥¼ íšŒê·€ ì§ì„ ì´ ë” ì˜ ì„¤ëª…í•˜ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ í˜„ìƒì„ ì‹¬ìŠ¨â€™s íŒ¨ëŸ¬ë…ìŠ¤ë¼ê³ 
    ë¶€ë¥¸ë‹¤.
    9) ì¢… ë³€ìˆ˜ê°€ ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë¸ 2ê°€ ëª¨ë¸ 1 ë³´ë‹¤ ë” ì¢‹ì€ ëª¨ë¸ì´ë¼ëŠ” ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.
    table = sm.stats.anova_lm(model1, model2) #anova
    print(table)
    ^à¼ˆ df_resid ssr df_diff ss_diff F Pr(>F)
    ^à¼ˆ 0 195.0 5228.862451 0.0 NaN NaN NaN
    ^à¼ˆ 1 193.0 1044.226281 2.0 4184.63617 386.714449 3.071739e-68
    ëª¨ë¸ 2ëŠ” ëª¨ë¸ 1ì„ í¬í•¨í•˜ëŠ” Full ëª¨ë¸ê³¼ Reduced ëª¨ë¸ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ë‘ ëª¨ë¸ ì‚¬ì´ì˜ í†µê³„ì  ìœ ì˜
    ì„±ì„ F ê²€ì •ì„ í†µí•˜ì—¬ ë³´ì¼ ìˆ˜ ìˆë‹¤.
    â€¢ ê·€ë¬´ê°€ì„¤ ğ»0
    : Reduced ëª¨ë¸ì´ ì•Œë§ìŒ.
    â€¢ ëŒ€ë¦½ê°€ì„¤ ğ»ğ´: Full ëª¨ë¸ì´ ì•Œë§ìŒ.
    260 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    ìœ„ì˜ ANOVA ì½”ë“œì˜ ê²°ê³¼ì—ì„œ F ê²€ì • í†µê³„ëŸ‰ 386.71ì— ëŒ€ì‘í•˜ëŠ” pâ€‘valueê°’ 3.07eâ€‘68ì´ ìœ ì˜ìˆ˜ì¤€
    5% í•˜ì—ì„œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ëª¨ë¸ 1 ë³´ë‹¤ ëª¨ë¸ 2ê°€ ë” ì•Œë§ì€ ëª¨ë¸ì´ë¼ íŒë‹¨í•œë‹¤.
    10) ëª¨ë¸ 2ì˜ ê³„ìˆ˜ì— ëŒ€í•œ ê²€ì •ê³¼ ê·¸ ì˜ë¯¸ë¥¼ í•´ì„í•´ ë³´ì„¸ìš”.
    model2.summary()
    ^à¼ˆ <class 'statsmodels.iolib.summary.Summary'>
    ^à¼ˆ ""
    ^à¼ˆ OLS Regression Results
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Dep. Variable: bill_length_mm Rà¼¡squared: 0.813
    ^à¼ˆ Model: OLS Adj. Rà¼¡squared: 0.810
    ^à¼ˆ Method: Least Squares Fà¼¡statistic: 279.2
    ^à¼ˆ Date: í† , 28 10 2023 Prob (Fà¼¡statistic): 6.28e-70
    ^à¼ˆ Time: 14:03:46 Log-Likelihood: -443.81
    ^à¼ˆ No. Observations: 197 AIC: 895.6
    ^à¼ˆ Df Residuals: 193 BIC: 908.8
    ^à¼ˆ Df Model: 3
    ^à¼ˆ Covariance Type: nonrobust
    ^à¼ˆ â†©
    ========================================================================================
    ^à¼ˆ coef std err t P>|t| [0.025 0.975]
    ^à¼ˆ â†©
    ----------------------------------------------------------------------------------------
    ^à¼ˆ Intercept 14.5776 2.855 5.107 0.000 8.947 20.208
    ^à¼ˆ species[T.Chinstrap] 9.8865 0.446 22.159 0.000 9.007 10.766
    ^à¼ˆ species[T.Gentoo] 12.9128 0.638 20.243 0.000 11.655 14.171
    ^à¼ˆ bill_depth_mm 1.3204 0.156 8.448 0.000 1.012 1.629
    ^à¼ˆ ==============================================================================
    ^à¼ˆ Omnibus: 0.570 Durbin-Watson: 2.084
    ^à¼ˆ Prob(Omnibus): 0.752 Jarque-Bera (JB): 0.322
    ^à¼ˆ Skew: -0.074 Prob(JB): 0.851
    ^à¼ˆ Kurtosis: 3.132 Cond. No. 304.
    ^à¼ˆ ==============================================================================
    ^à¼ˆ
    ^à¼ˆ Notes:
    ^à¼ˆ [1] Standard Errors assume that the covariance matrix of the errors is correctly â†©
    specified.
    ^à¼ˆ ""
    íšŒê·€ë¶„ì„ì˜ ê²°ê³¼ ëª¨í˜•ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê³ , ëª¨ë“  ê³„ìˆ˜ ì—­ì‹œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜
    ìˆë‹¤.
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 261
    â€¢ ë¶€ë¦¬ ê¹Šì´ì— ëŒ€ì‘í•˜ëŠ” ê³„ìˆ˜ëŠ” 1.3204ë¡œ, ì˜ë¯¸ëŠ” ë¶€ë¦¬ê¹Šì´ 1mmê°€ ì¦ê°€í•˜ë©´, ë¶€ë¦¬ê¸¸ì´ê°€
    1.3204mmê°€ ì¦ê°€í•˜ëŠ” ê²½í–¥ì„±ì„ ë³´ì¸ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤.
    â€¢ ê¸°ì¤€ ë ˆë²¨ì´ ë˜ëŠ” ì•„ë¸ë¦¬ í­ê·„ ì¢…ì˜ ë¶€ë¦¬ê¹Šì´ì— ë”°ë¥¸ ë¶€ë¦¬ê¸¸ì´ ì¶”ì„¸ëŠ” 14.5776 + 1.3204 Ã—
    ğ‘ğ‘–ğ‘™ğ‘™ğ‘‘
    ğ‘’ğ‘ğ‘¡â„ë¥¼ ë”°ë¥¸ë‹¤.
    â€¢ species[T.Chinstrap] ë³€ìˆ˜ì˜ ê³„ìˆ˜ 9.8865, species[T.Gentoo] ë³€ìˆ˜ì˜ ê³„ìˆ˜ 12.9128ì—ì„œ ì¹œ
    ìŠ¤íŠ¸ë© í­ê·„ ì¢…ì€ ì•„ë¸ë¦¬ í­ê·„ ì¢…ë³´ë‹¤ í‰ê· ì ìœ¼ë¡œ ì•½ 9.88mm, ê²íˆ¬ í­ê·„ ì¢…ì€ ì•„ë¸ë¦¬ í­ê·„
    ì¢…ë³´ë‹¤ í‰ê· ì ìœ¼ë¡œ ì•½ 12.91mm ê°€ ê¸´ ê²½í–¥ì„±ì„ ë³´ì¸ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤.
    11) ëª¨ë¸ 2 ì— ì”ì°¨ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê³ , íšŒê·€ëª¨ë¸ ê°€ì •ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì¦ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
    import scipy.stats as stats
    # Set up the subplots: 1 row, 2 columns
    residuals = model2.resid
    fitted_values = model2.fittedvalues
    plt.figure(figsize=(16,8))
    ^à¼ˆ <Figure size 1600x800 with 0 Axes>
    plt.subplot(1,2,1)
    ^à¼ˆ <AxesSubplot:>
    plt.scatter(fitted_values, residuals);
    plt.subplot(1,2,2)
    ^à¼ˆ <AxesSubplot:>
    pg.qqplot(residuals, dist='norm', confidence=0.95);
    # Display the plots
    ^à¼ˆ <AxesSubplot:xlabel='Theoretical quantiles', ylabel='Ordered quantiles'>
    plt.tight_layout()
    plt.show()
    262 | ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´
    11
    36 38 40 42 44 46 48 50 52
    8
    6
    4
    2
    0
    2
    4
    6
    2 1 0 1 2
    Theoretical quantiles
    2
    1
    0
    1
    2
    Ordered quantiles
    R
    2 = 0.991
    ì”ì°¨ ê·¸ë˜í”„ì™€ ì”ì°¨ì˜ QQ plot ê·¸ë˜í”„ë¡œ ë³´ì•„ ì”ì°¨ì˜ ë“±ë¶„ì‚°ì„±ê³¼ ì •ê·œì„±ì„ ë§Œì¡±í•˜ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨
    ëœë‹¤.
    from scipy.stats import shapiro
    from statsmodels.stats.diagnostic import het_breuschpagan
    from statsmodels.stats.stattools import durbin_watson
    shapiro(residuals)
    ^à¼ˆ ShapiroResult(statistic=0.9919706583023071, pvalue=0.35017824172973633)
    durbin_watson(residuals)
    ^à¼ˆ 2.083836063916197
    labels = ['Lagrange multiplier statistic', 'pà¼¡value', 'fà¼¡value', 'f pà¼¡value']
    bp_test = het_breuschpagan(residuals, model2.model.exog)
    bp_result = dict(zip(labels, bp_test))
    bp_result
    ^à¼ˆ {'Lagrange multiplier statistic': 12.575027525429496, 'pà¼¡value': â†©
    0.005651859166962036, 'fà¼¡value': 4.3865720927834015, 'f pà¼¡value': 0.005177711883822766}
    ìœ ì˜ìˆ˜ì¤€ 5%í•˜ì—ì„œ ì”ì°¨ ì •ê·œì„±ì„ ê²€ì •í•˜ëŠ” Shapiroâ€‘Wilk ê²€ì •, ì”ì°¨ì˜ ë“±ë¶„ì‚°ì„±ì„ ê²€ì •í•˜ëŠ”
    Breuschâ€“Pagan ê²€ì •, ì”ì°¨ì˜ ë…ë¦½ì„±ì„ ê²€ì •í•˜ëŠ” Durbinâ€‘Watson ê²€ì •ì˜ ê²°ê³¼ê°€ íšŒê·€ëª¨ë¸ì˜ ê°€ì •
    ì„ ë§Œì¡±í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
    Durbinâ€‘Watson í†µê³„ëŸ‰ì˜ ê°’ì€ 0ì—ì„œ 4 ì‚¬ì´ì— ìˆìœ¼ë©°, 2 ê·¼ì²˜ì˜ ê°’ì€ ì”ì°¨ ê°„ì— ìƒê´€ê´€ê³„ê°€ ì—†ìŒì„
    ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê°’ì´ 2ë³´ë‹¤ í¬ë©´ ìŒì˜ ìƒê´€ê´€ê³„, 2ë³´ë‹¤ ì‘ìœ¼ë©´ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.
    12) ëª¨ë¸ 2 ì˜ ì”ì°¨ë¥¼ í†µí•˜ì—¬ ì˜í–¥ì , í˜¹ì€ ì´ìƒì¹˜ì˜ ìœ ë¬´ë¥¼ íŒë‹¨í•´ë³´ì„¸ìš”.
    ì±•í„°ë³„ ì—°ìŠµë¬¸ì œ í’€ì´ | 263
    influence = model2.get_influence()
    stud_res = influence.resid_studentized_external
    # 2. Identify observations with studentized residuals
    # greater than 3 in absolute value
    outliers = np.where(np.abs(stud_res) > 3)[0]
    # 3. Retrieve these rows from train_data
    outlier_data = train_data.iloc[outliers]
    outlier_data["bill_depth_mm"]
    ^à¼ˆ 14 21.1
    ^à¼ˆ Name: bill_depth_mm, dtype: float64
    outlier_data["bill_length_mm"]
    ^à¼ˆ 14 34.6
    ^à¼ˆ Name: bill_length_mm, dtype: float64
    print(outlier_data)
    ^à¼ˆ species island bill_length_mm ^^. body_mass_g sex year
    ^à¼ˆ 14 Adelie Torgersen 34.6 ^^. 4400.0 male 2007
    ^à¼ˆ
    ^à¼ˆ [1 rows x 8 columns]
    ìŠ¤íŠœë˜íŠ¸í™” ì”ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 3 í‘œì¤€í¸ì°¨ ë°–ìœ¼ë¡œ ë²—ì–´ë‚˜ ìˆëŠ” í‘œë³¸ì€ ìœ„ì™€ ê°™ë‹¤. Adelie í‘œë³¸ì˜ ê²½ìš°
    ë¹„ìŠ·í•œ ë¶€ë¦¬ ê¹Šì´ì˜ í‘œë³¸ë“¤ê³¼ëŠ” ë„ˆë¬´ ë§ì€ ì°¨ì´ë¥¼ ë³´ì´ë¯€ë¡œ ì´ìƒì¹˜ë¡œ íŒë‹¨í•œë‹¤.
    """