{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b05dd9",
   "metadata": {},
   "source": [
    "#### [`Chapter-02_Tokens-of-thought-natural-language-words`](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/Chapter-02_Tokens-of-thought-natural-language-words.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1cdb6b",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"Trust me, though, the words were on their way, and when \"\n",
    "        \"they arrived, Liesel would hold them in her hands like \"\n",
    "        \"the clouds, and she would wring them out, like the rain.\")\n",
    "tokens = text.split()  # <1>\n",
    "tokens[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92fe27",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'\\w+(?:\\'\\w+)?|[^\\w\\s]'  # <1>\n",
    "texts = [text]\n",
    "texts.append(\"There's no such thing as survival of the fittest. \"\n",
    "             \"Survival of the most adequate, maybe.\")\n",
    "tokens = list(re.findall(pattern, texts[-1]))\n",
    "tokens[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a07ef",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f02408",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[8:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631a5f4",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8edb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[16:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ef525",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab = sorted(set(tokens))  # <1>\n",
    "' '.join(vocab[:12])  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492812f8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25843c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(tokens)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c04fe",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc585a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007f91f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy  # <1>\n",
    "spacy.cli.download('en_core_web_sm')  # <2>\n",
    "nlp = spacy.load('en_core_web_sm')  # <3>\n",
    "doc = nlp(texts[-1])\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f35ac",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tok.text for tok in doc]\n",
    "tokens[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70090a59",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[9:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b8245",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea786076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "sentence = list(doc.sents)[0]  # <1>\n",
    "svg = displacy.render(sentence, style=\"dep\")\n",
    "open('sentence_diagram.svg', 'w').write(svg)  # <2>\n",
    "import requests\n",
    "text = requests.get('https://proai.org/nlpia2-ch2.adoc').text\n",
    "f'{round(len(text) / 10_000)}0k'  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f1c42",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "%timeit nlp(text)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb75dda",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b276d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{round(len(text) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93205e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841755ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "f'{round(len(list(doc)) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152c394",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{round(len(doc) / 1_000 / 4.67)}kWPS'  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf281a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c476b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528287b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=nlp.pipe_names)\n",
    "%timeit nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061dabb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04029c6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4438f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "%timeit word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b0045",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "f'{round(len(tokens) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6b393",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88048e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\w+(?:\\'\\w+)?|[^\\w\\s]'\n",
    "tokens = re.findall(pattern, text)  # <1>\n",
    "f'{round(len(tokens) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995e8b3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024abd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2187f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097268c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), analyzer='char')\n",
    "vectorizer.fit(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861b240",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpevocab_list = [\n",
    "   sorted((i, s) for s, i in vectorizer.vocabulary_.items())]\n",
    "bpevocab_dict = dict(bpevocab_list[0])\n",
    "list(bpevocab_dict.values())[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50975e92",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c272f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.transform(texts)\n",
    "df = pd.DataFrame(\n",
    "    vectors.todense(), \n",
    "    columns=vectorizer.vocabulary_)\n",
    "df.index = [t[:8] + '...' for t in texts]\n",
    "df = df.T\n",
    "df['total'] = df.T.sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8de21",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('total').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc4a35",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n'] = [len(tok) for tok in vectorizer.vocabulary_]\n",
    "df[df['n'] > 1].sort_values('total').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b90ad2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd733c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_text = 'Hiking home now'\n",
    "hi_text.startswith('Hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92743ae8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca05e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\w+(?:\\'\\w+)?|[^\\w\\s]'  # <1>\n",
    "'Hi' in re.findall(pattern, hi_text)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894160c6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Hi' == re.findall(pattern, hi_text)[0]  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aee48f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98505c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "onehot_vectors = np.zeros(\n",
    "    (len(tokens), vocab_size), int)  # <1>\n",
    "for i, tok in enumerate(tokens):\n",
    "    if tok not in vocab:\n",
    "        continue\n",
    "    onehot_vectors[i, vocab.index(tok)] = 1  # <2>\n",
    "df_onehot = pd.DataFrame(onehot_vectors, columns=vocab)\n",
    "df_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5faad",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot.iloc[:,:8].replace(0, '')  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb7ba8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ee5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy  # <1>\n",
    "from nlpia2.spacy_language_model import load  # <2>\n",
    "nlp = load('en_core_web_sm')  # <3>\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa720a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eeef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(texts[-1])\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87e9cd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0541f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tok.text for tok in doc]  # <1>\n",
    "tokens[:9]  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f0c5c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd78520",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[9:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c57f54",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c616126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "sentence = list(doc.sents)[0] # <1>\n",
    "displacy.serve(sentence, style=\"dep\")\n",
    "!firefox 127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a42d3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "text = requests.get('https://proai.org/nlpia2-ch2.adoc').text\n",
    "f'{round(len(text) / 10_000)}0k'  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87eb8f2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c578b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia2.spacy_language_model import load\n",
    "nlp = load('en_core_web_sm')\n",
    "%timeit nlp(text)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2e8d4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ddc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{round(len(text) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c4aa4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45307d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "f'{round(len(list(doc)) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18e6f1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45be9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{round(len(doc) / 1_000 / 4.67)}kWPS'  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87507dab",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb45da",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load('en_core_web_sm', disable=['tok2vec', 'tagger', 'parser'])\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2d867",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e082f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd961b4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2654076",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4103929",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\w+(?:\\'\\w+)?|[^\\w\\s]'\n",
    "tokens = re.findall(pattern, text)  # <1>\n",
    "f'{round(len(tokens) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc8d57",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f27351",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), analyzer='char')\n",
    "vectorizer.fit(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d9bc2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb56f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpevocab_list = [\n",
    "   sorted((i, s) for s, i in vectorizer.vocabulary_.items())]\n",
    "bpevocab_dict = dict(bpevocab_list[0])\n",
    "list(bpevocab_dict.values())[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b003d92",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.transform(texts)\n",
    "df = pd.DataFrame(\n",
    "    vectors.todense(),\n",
    "    columns=vectorizer.vocabulary_)\n",
    "df.index = [t[:8] + '...' for t in texts]\n",
    "df = df.T\n",
    "df['total'] = df.T.sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9760a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9290cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('total').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31470a0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n'] = [len(tok) for tok in vectorizer.vocabulary_]\n",
    "df[df['n'] > 1].sort_values('total').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ed4f9c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_text = 'Hiking home now'\n",
    "hi_text.startswith('Hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d393f5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\w+(?:\\'\\w+)?|[^\\w\\s]'  # <1>\n",
    "'Hi' in re.findall(pattern, hi_text)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d84bc",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Hi' == re.findall(pattern, hi_text)[0]  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da879774",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = sorted(set(re.findall(pattern, text)))\n",
    "bow[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a79b0c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow[9:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817ada8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow[19:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d9609",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([2, 3, 4])\n",
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8f5ee",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "(v1 * v2).sum()  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05ee4c",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40381194",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([x1 * x2 for x1, x2 in zip(v1, v2)])  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280efeca",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "texts.append(\n",
    "  \"If conscience and empathy were impediments to the advancement of \"\n",
    "  \"self-interest, then we would have evolved to be amoral sociopaths.\"\n",
    "  )  # <1>\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(texts[-1])[:6]\n",
    "tokens[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6e3ba",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2454514",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[8:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6dd27",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[16:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020fce9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcf71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Nice guys finish first.\"  # <1>\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<11}{token.pos_:<10}{token.dep:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6f743",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f52c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"西安是一座举世闻名的文化古城\")  # <1>\n",
    "list(seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fae741",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711cab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"西安是一座举世闻名的文化古城\", cut_all=True)  # <1>\n",
    "list(seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ff90c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a688acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from jieba import posseg\n",
    "words = posseg.cut(\"西安是一座举世闻名的文化古城\")\n",
    "jieba.enable_paddle()  # <1>\n",
    "words = posseg.cut(\"西安是一座举世闻名的文化古城\", use_paddle=True)\n",
    "list(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da1114",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"zh_core_web_sm\")  # <1>\n",
    "nlpzh = spacy.load(\"zh_core_web_sm\")\n",
    "doc = nlpzh(\"西安是一座举世闻名的文化古城\")\n",
    "[(tok.text, tok.pos_) for tok in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37b073",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import casual_tokenize\n",
    "texts.append(\"@rickrau mind BLOOOOOOOOWWWWWN by latest lex :*) !!!!!!!!\")\n",
    "casual_tokenize(texts[-1], reduce_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eaead9",
   "metadata": {},
   "source": [
    "#### .Broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e25dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = (\"https://gitlab.com/tangibleai/nlpia/-/raw/master/\"\n",
    "       \"src/nlpia/data/stopword_lists.json\")\n",
    "response = requests.get(url)\n",
    "stopwords = response.json()['exhaustive']  # <1>\n",
    "tokens = 'the words were just as I remembered them'.split()  # <2>\n",
    "tokens_without_stopwords = [x for x in tokens if x not in stopwords]\n",
    "print(tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddf047",
   "metadata": {},
   "source": [
    "#### .Broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daef347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42792d",
   "metadata": {},
   "source": [
    "#### .Broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9dd59",
   "metadata": {},
   "source": [
    "#### .Broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sw for sw in stopwords if len(sw) == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e20177",
   "metadata": {},
   "source": [
    "#### .Broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba525cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5663e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['House', 'Visitor', 'Center']\n",
    "normalized_tokens = [x.lower() for x in tokens]\n",
    "print(normalized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90041c10",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a896a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(phrase):\n",
    "    return ' '.join([re.findall('^(.*ss|.*?)(s)?$',\n",
    "        word)[0][0].strip(\"'\") for word in phrase.lower().split()])\n",
    "stem('houses')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bd6c9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem(\"Doctor House's calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61573734",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed47b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "' '.join([stemmer.stem(w).strip(\"'\") for w in\n",
    "  \"dish washer's fairly washed dishes\".split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfc196",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "' '.join([stemmer.stem(w).strip(\"'\") for w in\n",
    "  \"dish washer's fairly washed dishes\".split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ad982",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93179fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f76c3f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30916b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f75c4d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"better\")  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee538df",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd86fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"better\", pos=\"a\")  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ec287",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"good\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937e520",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.stem('goodness')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b7cfa",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"better good goods goodness best\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d949f8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1da614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "sa.lexicon  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749a953",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(tok, score) for tok, score in sa.lexicon.items()\n",
    "  if \" \" in tok]  # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce9df5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.polarity_scores(text=\\\n",
    "  \"Python is very readable and it's great for NLP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f8084",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.polarity_scores(text=\\\n",
    "  \"Python is not a bad choice for most applications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395e10b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abca93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Absolutely perfect! Love it! :-) :-) :-)\",\n",
    "          \"Horrible! Completely useless. :(\",\n",
    "          \"It was OK. Some good and some bad things.\"]\n",
    "for doc in corpus:\n",
    "    scores = sa.polarity_scores(doc)\n",
    "    print('{:+}: {}'.format(scores['compound'], doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503391a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a53994",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('https://proai.org/movie-reviews.csv.gz',\n",
    "    index_col=0)\n",
    "movies.head().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ccb085",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff857c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a203f22",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.width = 75  # <1>\n",
    "from nltk.tokenize import casual_tokenize  # <2>\n",
    "bows = []\n",
    "from collections import Counter  # <3>\n",
    "for text in movies.text:\n",
    "    bows.append(Counter(casual_tokenize(text)))\n",
    "df_movies = pd.DataFrame.from_records(bows)  # <4>\n",
    "df_movies = df_movies.fillna(0).astype(int)  # <5>\n",
    "df_movies.shape  # <6>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d484ba",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8f3bf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()[list(bows[0].keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425b75d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1af887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(df_movies, movies.sentiment > 0)  # <1>\n",
    "movies['pred_senti'] = (\n",
    "  nb.predict_proba(df_movies))[:, 1] * 8 - 4  # <2>\n",
    "movies['error'] = movies.pred_senti - movies.sentiment\n",
    "mae = movies['error'].abs().mean().round(1)  # <3>\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2e36e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f598ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['senti_ispos'] = (movies['sentiment'] > 0).astype(int)\n",
    "movies['pred_ispos'] = (movies['pred_senti'] > 0).astype(int)\n",
    "columns = [c for c in movies.columns if 'senti' in c or 'pred' in c]\n",
    "movies[columns].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e387d2a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(movies.pred_ispos ==\n",
    "  movies.senti_ispos).sum() / len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643164c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5935bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('https://proai.org/product-reviews.csv.gz')\n",
    "products.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14eec8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21438194",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b36d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = []\n",
    "for text in products['text']:\n",
    "    bows.append(Counter(casual_tokenize(text)))\n",
    "df_products = pd.DataFrame.from_records(bows)\n",
    "df_products = df_products.fillna(0).astype(int)\n",
    "df_products.shape # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c023bf8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_bows = pd.concat([df_movies, df_products])\n",
    "df_all_bows.columns  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076badee",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc302c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(df_movies.columns)  # <1>\n",
    "df_products = df_all_bows.iloc[len(movies):]  # <2>\n",
    "df_products = df_products[vocab]  # <3>\n",
    "df_products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3fb37",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.shape  # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb42ed",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e224ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "products['senti_ispos'] = (products['sentiment'] > 0).astype(int)\n",
    "products['pred_ispos'] = nb.predict(df_products).astype(int)\n",
    "correct = (products['pred_ispos']\n",
    "        == products['senti_ispos'])  # <1>\n",
    "correct.sum() / len(products)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
