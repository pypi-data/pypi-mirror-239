{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf3ba2e",
   "metadata": {},
   "source": [
    "#### [`Chapter-12_Getting-chatty-dialog-engines`](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/Chapter-12_Getting-chatty-dialog-engines.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af4014",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada64411",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad Snisar, Ruslan Borisov build ConvoHub w/ spaCy.\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43153a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00061b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar, ruslan borisov build convoHub w/ spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d5c09",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed255a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar ruslan borisov convoHub spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10cba11",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd936bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_proper_nouns(\n",
    "        context, key=\"user_text\",  # <1>\n",
    "        pos=\"PROPN\", ent_type=None):  # <2>\n",
    "    doc = nlp(context.get(key, ''))  # <3>\n",
    "    names = []\n",
    "    i = 0\n",
    "    while i < len(doc):\n",
    "        tok = doc[i]\n",
    "        ent = []\n",
    "        if ((pos is None or tok.pos_ == pos)\n",
    "                and (ent_type is None or tok.ent_type_ != ent_type)):\n",
    "            for k, t in enumerate(doc[i:]):\n",
    "                if not ((pos is None or t.pos_ == pos)\n",
    "                    and (ent_type is None or t.ent_type_\n",
    "                        != ent_type)):\n",
    "                    break\n",
    "                ent.append(t.text)\n",
    "            names.append(\" \".join(ent))\n",
    "        i += len(ent) + 1\n",
    "    return {'proper_nouns': names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ec2b1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a848ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Ruslan Borisov and Vlad Snisar rebuilt ConvoHub.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93981ffa",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mathtext\n",
    "from mathtext.predict_intent import predict_intents_list\n",
    "predict_intents_list('you are mean forty 2')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8da8df",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb712e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_intents_list('you are jerk infinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d513cb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_data(start, stop, step, question_num=None):\n",
    "    \"\"\" Generate list of possible questions with their contexts \"\"\"\n",
    "    seq = seq2str(start, stop, step)\n",
    "    templates = [\n",
    "        f\"Let's practice counting {seq2str(start, stop, step)}... \" \\\n",
    "        + f\"What is the next number in the sequence after {stop}?\",\n",
    "        f\"What number comes {step} after {stop}?\\n{seq}\",\n",
    "        f\"We're counting by {step}s. \" \\\n",
    "        + f\"What number is 1 after {stop}?\\n{seq}\",\n",
    "        f\"What is {step} number up from {stop}?\\n{seq}\",\n",
    "        f\"If we count up {step} from {stop}, \" \\\n",
    "        + f\"what number is next?\\n{seq}\",\n",
    "    ]\n",
    "    questions = []\n",
    "    for quest in templates:\n",
    "        questions.append({\n",
    "             \"question\": quest,\n",
    "             \"answer\": stop + step,\n",
    "             \"start\": start,\n",
    "             \"stop\": stop,\n",
    "             \"step\": step,\n",
    "             })\n",
    "    return questions[question_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d0981",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Replicate\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = '<your_API_key_here>'\n",
    "llm = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:\" +\n",
    "    \"df7690\",  # <1>\n",
    "    input={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_length\": 100,\n",
    "        \"top_p\": 1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c3d5f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor \n",
    "    chatbot Rori and a user who might be a student \n",
    "    in Africa or a parent. \n",
    "\n",
    "    Human says: {message}\n",
    "    Chatbot responds:\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"message\"],  # <1>\n",
    "    template=template)       \n",
    "chain = LLMChain(\n",
    "    llm=llm, verbose=True, prompt=prompt  # <2>\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc12b0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"Hi Bot! My name is Maria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07201d29",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee4e3e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor chatbot\n",
    "    Rori and a user who might be a student in Africa or a parent. \n",
    "    The chatbot introduces itself and asks if it's talking to a\n",
    "    student or to a parent. \n",
    "    If the user is a parent, Rori asks the parent for \n",
    "    permission for the child to use Rori over Whatsapp. \n",
    "    If the user is a student, Rori asks the student to\n",
    "     call their parents. \n",
    "    If the parent agrees, Rori thanks them and asks to give the phone to the student. \n",
    "    Provide the tutor's next response based on the conversation history.\n",
    "\n",
    "    {chat_history}\n",
    "    Parent: {message}\n",
    "    Tutor:\"\"\"\n",
    "onboarding_prompt = PromptTemplate(\n",
    "    input_variables = [\"chat_history\", \"message\"],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc9226",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a182e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50735024",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = ConversationBufferMemory\n",
    "    )\n",
    "onboarding_chain.prompt = onboarding_prompt\n",
    "onboarding_chain.predict(message=\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed77bb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain.predict(message=\"I'm a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581654e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46eafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_pt = \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88bbc26",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathConversation():\n",
    "   def __init__(self, llm, prompt_string):\n",
    "      self.llm = llm\n",
    "      self.memory = \\\n",
    "        ConversationBufferMemory(memory_key='history',\n",
    "                                  ai_prefix='tutor',\n",
    "                                 human_prefix=\"user\")\n",
    "    self.convo_chain = \\\n",
    "        ConversationChain(llm=llm, memory=self.memory)\n",
    "    self.convo_chain.prompt = \\\n",
    "        PromptTemplate(\n",
    "            input_variables=[\"history\", \"input\"],\n",
    "            template=prompt_string)\n",
    "\n",
    "  def answer(self, user_input):\n",
    "      return self.convo_chain.predict(input=user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a149c64",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e07328",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo = MathConversation(llm, onboarding_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5df2a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"I am a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad234397",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"Yes, I agree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee29c4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_quiz_pt = \"\"\"\n",
    "You are a math teacher that's teaching math to a third-grade\n",
    "student. Prompt the student to complete number sequences\n",
    "from the following list and compare their answer with the\n",
    "last number in the sequence:\n",
    "  - 9,10,11,12\n",
    "  - 38,39,40,41\n",
    "  - 2,4,6,8\n",
    "  - 1,5,9,13\n",
    "  {history}\n",
    "  student:{input}\n",
    "  tutor:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e542b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1875e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_convo = MathConversation(llm, math_quiz_pt)\n",
    "math_convo.answer(\"Let's start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ff02c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_convo.answer(\"12\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
