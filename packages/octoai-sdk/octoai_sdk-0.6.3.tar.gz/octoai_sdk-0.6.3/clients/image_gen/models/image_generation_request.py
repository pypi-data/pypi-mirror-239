# coding: utf-8

"""
    FastAPI

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 0.1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from typing import Dict, Optional, Union

from pydantic.v1 import (
    BaseModel,
    Field,
    StrictBool,
    StrictFloat,
    StrictInt,
    StrictStr,
    confloat,
    conint,
    constr,
)

from clients.image_gen.models.image_encoding import ImageEncoding
from clients.image_gen.models.scheduler import Scheduler
from clients.image_gen.models.sdxl_styles import SDXLStyles


class ImageGenerationRequest(BaseModel):
    """
    Generate one or more images based on the given parameters.  # noqa: E501
    """

    prompt: constr(strict=True, max_length=10000) = Field(
        ..., description="Text describing the image content to generate."
    )
    prompt_2: Optional[constr(strict=True, max_length=10000)] = Field(
        None,
        description="Text with a high-level description of the image to generate. Used only by SD XL.",
    )
    negative_prompt: Optional[constr(strict=True, max_length=10000)] = Field(
        None, description="Text describing image traits to avoid during generation."
    )
    negative_prompt_2: Optional[constr(strict=True, max_length=10000)] = Field(
        None,
        description="Text with a high level description of things to avoid during generation. Used only by SD XL.",
    )
    checkpoint: Optional[StrictStr] = Field(
        None, description="Checkpoint to be used during image generation"
    )
    textual_inversions: Optional[Dict[str, StrictStr]] = Field(
        None,
        description="A dictionary of textual inversion to be used during image generation. Textual Inversion as key and trigger words as value.",
    )
    loras: Optional[Dict[str, Union[StrictFloat, StrictInt]]] = Field(
        None,
        description="A dictionary of LoRAs to apply. LoRAs as key and its weight (float) as value.",
    )
    sampler: Optional[Scheduler] = None
    height: Optional[StrictInt] = Field(
        None,
        description="Integer representing the height of image to generate. None will default to 512 for SD 1.5 and 1024 for SD XL. Supported resolutions (w,h): SDXL={(1536, 640), (768, 1344), (832, 1216), (1344, 768), (1152, 896), (640, 1536), (1216, 832), (896, 1152), (1024, 1024)}, SD1.5={(512, 512), (1024, 576), (640, 512), (512, 704), (576, 768), (512, 768), (640, 768), (576, 1024), (768, 512)}",
    )
    width: Optional[StrictInt] = Field(
        None,
        description="Integer representing the width of image to generate. None will default to 512 for SD 1.5 and 1024 for SD XL. Supported resolutions (w,h): SDXL={(1536, 640), (768, 1344), (832, 1216), (1344, 768), (1152, 896), (640, 1536), (1216, 832), (896, 1152), (1024, 1024)}, SD1.5={(512, 512), (1024, 576), (640, 512), (512, 704), (576, 768), (512, 768), (640, 768), (576, 1024), (768, 512)}",
    )
    cfg_scale: Optional[
        Union[confloat(le=20.0, strict=True), conint(le=20, strict=True)]
    ] = Field(
        12.0,
        description="Floating-point number represeting how closely to adhere to prompt description. Must be a positive number and less than or equal to 20.0.",
    )
    steps: Optional[conint(strict=True, le=200)] = Field(
        30,
        description="Integer repreenting how many steps of diffusion to run. Must be greater than 0 and less than or equal to 200.",
    )
    num_images: Optional[conint(strict=True, le=10)] = Field(
        1,
        description="Integer representing how many output images to generate with a single prompt/configuration.",
    )
    seed: Optional[StrictInt] = Field(
        None,
        description="Integer number representing the seed of random generators. Fixing random seed is useful when attempting to generate a specific image. Must be greater than 0 and less than 2^32.",
    )
    init_image: Optional[StrictStr] = Field(
        None,
        description="Starting point image encoded in b64 string for Image to Image generation mode.",
    )
    mask_image: Optional[StrictStr] = Field(
        None,
        description="b64 encoded mask image for inpainting. White area should indicate where to paint.",
    )
    strength: Optional[
        Union[confloat(le=1.0, ge=0.0, strict=True), conint(le=1, ge=0, strict=True)]
    ] = Field(
        0.8,
        description="Floating-point number indicating how much creative the Image to Image generation mode should be. Must be greater than 0 and less than or equal to 1.0.",
    )
    style_preset: Optional[SDXLStyles] = None
    use_refiner: Optional[StrictBool] = Field(
        True,
        description="Whether to enable and apply the SDXL refiner model to the image generation.",
    )
    high_noise_frac: Optional[
        Union[confloat(le=1.0, ge=0.0, strict=True), conint(le=1, ge=0, strict=True)]
    ] = Field(
        0.8,
        description="Floating-point number that defines the fraction of steps to perform with the base model. Used only by SD XL. Must be greater than or equal to 0.0 and less than or equal to 1.0.",
    )
    enable_safety: Optional[StrictBool] = Field(
        False,
        description="Boolean defining whether to use safety checker system on generated outputs or not.",
    )
    image_encoding: Optional[ImageEncoding] = None
    force_asset_download: Optional[StrictBool] = Field(
        False,
        description="[Internal] Boolean defining if assets must be re-downloaded into the cache even if present.",
    )
    force_asset_gpu_copy: Optional[StrictBool] = Field(
        False,
        description="[Internal] Boolean defining if assets must to be copied into the GPU even if present.",
    )
    __properties = [
        "prompt",
        "prompt_2",
        "negative_prompt",
        "negative_prompt_2",
        "checkpoint",
        "textual_inversions",
        "loras",
        "sampler",
        "height",
        "width",
        "cfg_scale",
        "steps",
        "num_images",
        "seed",
        "init_image",
        "mask_image",
        "strength",
        "style_preset",
        "use_refiner",
        "high_noise_frac",
        "enable_safety",
        "image_encoding",
        "force_asset_download",
        "force_asset_gpu_copy",
    ]

    class Config:
        """Pydantic configuration"""

        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> ImageGenerationRequest:
        """Create an instance of ImageGenerationRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self):
        """Returns the dictionary representation of the model using alias"""
        _dict = self.dict(by_alias=True, exclude={}, exclude_none=True)
        return _dict

    @classmethod
    def from_dict(cls, obj: dict) -> ImageGenerationRequest:
        """Create an instance of ImageGenerationRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return ImageGenerationRequest.parse_obj(obj)

        _obj = ImageGenerationRequest.parse_obj(
            {
                "prompt": obj.get("prompt"),
                "prompt_2": obj.get("prompt_2"),
                "negative_prompt": obj.get("negative_prompt"),
                "negative_prompt_2": obj.get("negative_prompt_2"),
                "checkpoint": obj.get("checkpoint"),
                "textual_inversions": obj.get("textual_inversions"),
                "loras": obj.get("loras"),
                "sampler": obj.get("sampler"),
                "height": obj.get("height"),
                "width": obj.get("width"),
                "cfg_scale": obj.get("cfg_scale")
                if obj.get("cfg_scale") is not None
                else 12.0,
                "steps": obj.get("steps") if obj.get("steps") is not None else 30,
                "num_images": obj.get("num_images")
                if obj.get("num_images") is not None
                else 1,
                "seed": obj.get("seed"),
                "init_image": obj.get("init_image"),
                "mask_image": obj.get("mask_image"),
                "strength": obj.get("strength")
                if obj.get("strength") is not None
                else 0.8,
                "style_preset": obj.get("style_preset"),
                "use_refiner": obj.get("use_refiner")
                if obj.get("use_refiner") is not None
                else True,
                "high_noise_frac": obj.get("high_noise_frac")
                if obj.get("high_noise_frac") is not None
                else 0.8,
                "enable_safety": obj.get("enable_safety")
                if obj.get("enable_safety") is not None
                else False,
                "image_encoding": obj.get("image_encoding"),
                "force_asset_download": obj.get("force_asset_download")
                if obj.get("force_asset_download") is not None
                else False,
                "force_asset_gpu_copy": obj.get("force_asset_gpu_copy")
                if obj.get("force_asset_gpu_copy") is not None
                else False,
            }
        )
        return _obj
