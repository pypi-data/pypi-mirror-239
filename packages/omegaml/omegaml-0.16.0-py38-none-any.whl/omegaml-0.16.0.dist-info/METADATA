Metadata-Version: 2.1
Name: omegaml
Version: 0.16.0
Summary: An open source DataOps, MLOps platform for humans
Home-page: https://omegaml.io/
Author: Patrick Senti
Author-email: patrick.senti@omegaml.io
License: Apache 2.0 + "No Sell, Consulting Yes" License Condition
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Development Status :: 4 - Beta
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development
Classifier: Operating System :: POSIX :: Linux
Classifier: License :: OSI Approved :: Apache Software License
Description-Content-Type: text/x-rst
License-File: LICENSE
License-File: LICENSE-NOSELLCLAUSE
License-File: LICENSES-THIRDPARTY
License-File: NOTICE
Requires-Dist: celery <6.0,>5
Requires-Dist: importlib-metadata <5.0
Requires-Dist: joblib >=0.9.4
Requires-Dist: jupyter-client >=4.1.1
Requires-Dist: mongoengine >=0.24.1
Requires-Dist: pandas >=2.0.0
Requires-Dist: numpy >=1.16.4
Requires-Dist: scipy >=0.17.0
Requires-Dist: scikit-learn >=0.21
Requires-Dist: PyYAML >=3.12
Requires-Dist: flask-restx >=1.1.0
Requires-Dist: croniter >=0.3.30
Requires-Dist: nbformat >=4.0.1
Requires-Dist: nbconvert >=6.4.0
Requires-Dist: dill <0.3.6,>=0.3.2
Requires-Dist: callable-pip >=1.0.0
Requires-Dist: appdirs >=1.4.3
Requires-Dist: cron-descriptor >=1.2.31
Requires-Dist: docopt >=0.6.2
Requires-Dist: requests >=2.20.0
Requires-Dist: tqdm >=4.32.2
Requires-Dist: honcho >=1.0.1
Requires-Dist: tabulate >=0.8.2
Requires-Dist: smart-open
Requires-Dist: imageio >=2.3.0
Requires-Dist: psutil >=5.8
Requires-Dist: cachetools >=5.0.0
Requires-Dist: apispec >=5.2.2
Requires-Dist: marshmallow >=3.17.0
Provides-Extra: all
Requires-Dist: tables >=3.7 ; extra == 'all'
Requires-Dist: matplotlib ~=3.5 ; extra == 'all'
Requires-Dist: seaborn ~=0.11 ; extra == 'all'
Requires-Dist: imageio ~=2.6 ; extra == 'all'
Requires-Dist: plotext ~=1.0 ; extra == 'all'
Requires-Dist: dashserve ; extra == 'all'
Requires-Dist: dash <2.9 ; extra == 'all'
Requires-Dist: sqlalchemy ; extra == 'all'
Requires-Dist: ipython-sql ; extra == 'all'
Requires-Dist: boto >=2.49.0 ; extra == 'all'
Requires-Dist: minibatch[all] >=0.5.0 ; extra == 'all'
Requires-Dist: jupyterlab ; extra == 'all'
Requires-Dist: jupyterhub ; extra == 'all'
Requires-Dist: notebook ; extra == 'all'
Requires-Dist: nbclassic ; extra == 'all'
Requires-Dist: snowflake-sqlalchemy >1.2.3 ; extra == 'all'
Provides-Extra: all-client
Requires-Dist: tables >=3.7 ; extra == 'all-client'
Requires-Dist: dashserve ; extra == 'all-client'
Requires-Dist: dash <2.9 ; extra == 'all-client'
Requires-Dist: sqlalchemy ; extra == 'all-client'
Requires-Dist: ipython-sql ; extra == 'all-client'
Requires-Dist: boto >=2.49.0 ; extra == 'all-client'
Requires-Dist: minibatch[all] >=0.5.0 ; extra == 'all-client'
Provides-Extra: client
Requires-Dist: tables >=3.7 ; extra == 'client'
Requires-Dist: dashserve ; extra == 'client'
Requires-Dist: dash <2.9 ; extra == 'client'
Requires-Dist: sqlalchemy ; extra == 'client'
Requires-Dist: ipython-sql ; extra == 'client'
Requires-Dist: boto >=2.49.0 ; extra == 'client'
Requires-Dist: minibatch[all] >=0.5.0 ; extra == 'client'
Provides-Extra: dashserve
Requires-Dist: dashserve ; extra == 'dashserve'
Requires-Dist: dash <2.9 ; extra == 'dashserve'
Provides-Extra: dev
Requires-Dist: pytest ; extra == 'dev'
Requires-Dist: twine ; extra == 'dev'
Requires-Dist: flake8 ; extra == 'dev'
Requires-Dist: mock ; extra == 'dev'
Requires-Dist: behave ; extra == 'dev'
Requires-Dist: splinter[selenium3] ; extra == 'dev'
Requires-Dist: ipdb ; extra == 'dev'
Requires-Dist: bumpversion ; extra == 'dev'
Provides-Extra: graph
Requires-Dist: matplotlib ~=3.5 ; extra == 'graph'
Requires-Dist: seaborn ~=0.11 ; extra == 'graph'
Requires-Dist: imageio ~=2.6 ; extra == 'graph'
Requires-Dist: plotext ~=1.0 ; extra == 'graph'
Provides-Extra: iotools
Requires-Dist: boto >=2.49.0 ; extra == 'iotools'
Provides-Extra: jupyter
Requires-Dist: jupyterlab ; extra == 'jupyter'
Requires-Dist: jupyterhub ; extra == 'jupyter'
Requires-Dist: notebook ; extra == 'jupyter'
Requires-Dist: nbclassic ; extra == 'jupyter'
Provides-Extra: mlflow
Requires-Dist: mlflow ~=1.21 ; extra == 'mlflow'
Provides-Extra: snowflake
Requires-Dist: snowflake-sqlalchemy >1.2.3 ; extra == 'snowflake'
Provides-Extra: sql
Requires-Dist: sqlalchemy ; extra == 'sql'
Requires-Dist: ipython-sql ; extra == 'sql'
Provides-Extra: streaming
Requires-Dist: minibatch[all] >=0.5.0 ; extra == 'streaming'
Provides-Extra: tables
Requires-Dist: tables >=3.7 ; extra == 'tables'
Provides-Extra: tensorflow
Requires-Dist: tensorflow ; extra == 'tensorflow'

omega|ml - MLOps for humans
===========================

with just a single line of code you can

- deploy machine learning models straight from Jupyter Notebook (or any other code)
- implement data pipelines quickly, without memory limitation, all from a Pandas-like API
- serve models and data from an easy to use REST API

Further, omega|ml is the fastest way to

- scale model training on the included scalable pure-Python compute cluster, on Spark or any other cloud
- collaborate on data science projects easily, sharing Jupyter Notebooks
- deploy beautiful dashboards right from your Jupyter Notebook, using dashserve

Quick start
-----------

Start the omega|ml server right from your laptop or virtual machine

.. code::

    $ wget https://raw.githubusercontent.com/omegaml/omegaml/master/docker-compose.yml
    $ docker-compose up -d

Jupyter Notebook is immediately available at http://localhost:8899 (`omegamlisfun` to login).
Any notebook you create will automatically be stored in the integrated omega|ml database, making collaboration a breeze.
The REST API is available at http://localhost:5000.

Already have a Python environment (e.g. Jupyter Notebook)?
Leverage the power of omega|ml by installing as follows:

.. code::

    # assuming you have started the server as per above
    $ pip install omegaml

Further information
-------------------

* Documentation: https://omegaml.github.io/omegaml/
* Contributions: http://bit.ly/omegaml-contribute

Examples
--------

.. code::

    # transparently store Pandas Series and DataFrames or any Python object
    om.datasets.put(df, 'stats')
    om.datasets.get('stats', sales__gte=100)

    # transparently store and get models
    clf = LogisticRegression()
    om.models.put(clf, 'forecast')
    clf = om.models.get('forecast')

    # run and scale models directly on the integrated Python or Spark compute cluster
    om.runtime.model('forecast').fit('stats[^sales]', 'stats[sales]')
    om.runtime.model('forecast').predict('stats')
    om.runtime.model('forecast').gridsearch(X, Y)

    # use the REST API to store and retrieve data, run predictions
    requests.put('/v1/dataset/stats', json={...})
    requests.get('/v1/dataset/stats?sales__gte=100')
    requests.put('/v1/model/forecast', json={...})


Use Cases
=========

omega|ml currently supports scikit-learn, Keras and Tensorflow out of the box.
Need to deploy a model from another framework? Open an issue at
https://github.com/omegaml/omegaml/issues or drop us a line at support@omegaml.io


Machine Learning Deployment
---------------------------

- deploy models to production with a single line of code
- serve and use models or datasets from a REST API


Data Science Collaboration
--------------------------

- get a fully integrated data science workplace within minutes
- easily share models, data, jupyter notebooks and reports with your collaborators

Centralized Data & Compute cluster
----------------------------------

- perform out-of-core computations on a pure-python or Apache Spark compute cluster
- have a shared NoSQL database (MongoDB), out of the box, working like a Pandas dataframe
- use a compute cluster to train your models with no additional setup

Scalability and Extensibility
-----------------------------

- scale your data science work from your laptop to team to production with no code changes
- integrate any machine learning framework or third party data science platform with a common API

Towards Data Science recently published an article on omega|ml:
https://towardsdatascience.com/omega-ml-deploying-data-machine-learning-pipelines-the-easy-way-a3d281569666

In addition omega|ml provides an easy-to-use extensions API to support any kind of models,
compute cluster, database and data source.

*Commercial Edition & Support*

https://omegaml.io

omega|ml Commercial Edition provides security on every level and is ready made for Kubernetes
deployment. It is licensed separately for on-premise, private or hybrid cloud.
Sign up at https://omegaml.io
